{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d95783b-a4ed-42ce-a7ce-dd9a9fb3ec38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG檢索器使用設備: cuda\n",
      "RAG檢索器初始化完成，連接到集合: testchunks\n",
      "檢索器統計: {'collection_name': 'testchunks', 'stats': {'row_count': 567}, 'device': 'cuda', 'model_dimension': 768}\n",
      "\n",
      "============================================================\n",
      "測試查詢: 人工智能的發展趨勢\n",
      "正在檢索查詢: '人工智能的發展趨勢...' (top_k=10)\n",
      "檢索完成，找到 10 個相關結果\n",
      "找到 10 個相關結果:\n",
      "1. 分數: 0.8554\n",
      "   來源: documents_dup_part_1_part_1_chunks/prod_documents_dup_part_1_part_1_path_merged_node_0_chunk_92_to_node_0_chunk_92.txt\n",
      "   內容: Chunk path: ./chunks_output/documents_dup_part_1_part_1_chunks/prod_documents_dup_part_1_part_1_path...\n",
      "\n",
      "2. 分數: 0.9175\n",
      "   來源: documents_dup_part_1_part_1_chunks/prod_documents_dup_part_1_part_1_path_merged_node_0_chunk_8_to_node_0_chunk_8.txt\n",
      "   內容: Chunk path: ./chunks_output/documents_dup_part_1_part_1_chunks/prod_documents_dup_part_1_part_1_path...\n",
      "\n",
      "3. 分數: 0.9766\n",
      "   來源: documents_dup_part_1_part_1_chunks/prod_documents_dup_part_1_part_1_path_merged_node_0_chunk_38_to_node_0_chunk_38.txt\n",
      "   內容: Chunk path: ./chunks_output/documents_dup_part_1_part_1_chunks/prod_documents_dup_part_1_part_1_path...\n",
      "\n",
      "4. 分數: 0.9884\n",
      "   來源: test_ml_chunks/prod_test_ml_path_merged_node_76_chunk_0_to_node_79_chunk_0.txt\n",
      "   內容: Chunk path: ./chunks_output/test_ml_chunks/prod_test_ml_path_merged_node_76_chunk_0_to_node_79_chunk...\n",
      "\n",
      "5. 分數: 1.0046\n",
      "   來源: test_ml_chunks/prod_test_ml_node_80_chunk_0.txt\n",
      "   內容: Chunk path: ./chunks_output/test_ml_chunks/prod_test_ml_node_80_chunk_0.txt\n",
      "Chunk name: prod_test_ml...\n",
      "\n",
      "\n",
      "============================================================\n",
      "測試查詢: 機器學習算法\n",
      "正在檢索查詢: '機器學習算法...' (top_k=10)\n",
      "檢索完成，找到 10 個相關結果\n",
      "找到 10 個相關結果:\n",
      "1. 分數: 0.7015\n",
      "   來源: test_ml_chunks/prod_test_ml_path_merged_node_38_chunk_0_to_node_40_chunk_0.txt\n",
      "   內容: Chunk path: ./chunks_output/test_ml_chunks/prod_test_ml_path_merged_node_38_chunk_0_to_node_40_chunk...\n",
      "\n",
      "2. 分數: 0.7234\n",
      "   來源: test_ml_chunks/prod_test_ml_path_merged_node_11_chunk_0_to_node_15_chunk_0.txt\n",
      "   內容: Chunk path: ./chunks_output/test_ml_chunks/prod_test_ml_path_merged_node_11_chunk_0_to_node_15_chunk...\n",
      "\n",
      "3. 分數: 0.7279\n",
      "   來源: test_ml_chunks/prod_test_ml_node_36_chunk_0.txt\n",
      "   內容: Chunk path: ./chunks_output/test_ml_chunks/prod_test_ml_node_36_chunk_0.txt\n",
      "Chunk name: prod_test_ml...\n",
      "\n",
      "4. 分數: 0.7512\n",
      "   來源: test_ml_chunks/prod_test_ml_node_26_chunk_0.txt\n",
      "   內容: Chunk path: ./chunks_output/test_ml_chunks/prod_test_ml_node_26_chunk_0.txt\n",
      "Chunk name: prod_test_ml...\n",
      "\n",
      "5. 分數: 0.7529\n",
      "   來源: test_ml_chunks/prod_test_ml_path_merged_node_48_chunk_0_to_node_49_chunk_0.txt\n",
      "   內容: Chunk path: ./chunks_output/test_ml_chunks/prod_test_ml_path_merged_node_48_chunk_0_to_node_49_chunk...\n",
      "\n",
      "\n",
      "============================================================\n",
      "測試查詢: 深度學習應用\n",
      "正在檢索查詢: '深度學習應用...' (top_k=10)\n",
      "檢索完成，找到 10 個相關結果\n",
      "找到 10 個相關結果:\n",
      "1. 分數: 0.8076\n",
      "   來源: test_ml_chunks/prod_test_ml_path_merged_node_18_chunk_0_to_node_21_chunk_0.txt\n",
      "   內容: Chunk path: ./chunks_output/test_ml_chunks/prod_test_ml_path_merged_node_18_chunk_0_to_node_21_chunk...\n",
      "\n",
      "2. 分數: 0.8128\n",
      "   來源: test_ml_chunks/prod_test_ml_path_merged_node_38_chunk_0_to_node_40_chunk_0.txt\n",
      "   內容: Chunk path: ./chunks_output/test_ml_chunks/prod_test_ml_path_merged_node_38_chunk_0_to_node_40_chunk...\n",
      "\n",
      "3. 分數: 0.8266\n",
      "   來源: test_ml_chunks/prod_test_ml_path_merged_node_48_chunk_0_to_node_49_chunk_0.txt\n",
      "   內容: Chunk path: ./chunks_output/test_ml_chunks/prod_test_ml_path_merged_node_48_chunk_0_to_node_49_chunk...\n",
      "\n",
      "4. 分數: 0.8443\n",
      "   來源: test_ml_chunks/prod_test_ml_path_merged_node_53_chunk_0_to_node_56_chunk_0.txt\n",
      "   內容: Chunk path: ./chunks_output/test_ml_chunks/prod_test_ml_path_merged_node_53_chunk_0_to_node_56_chunk...\n",
      "\n",
      "5. 分數: 0.8772\n",
      "   來源: test_ml_chunks/prod_test_ml_node_66_chunk_0.txt\n",
      "   內容: Chunk path: ./chunks_output/test_ml_chunks/prod_test_ml_node_66_chunk_0.txt\n",
      "Chunk name: prod_test_ml...\n",
      "\n",
      "\n",
      "============================================================\n",
      "測試查詢: 自然語言處理技術\n",
      "正在檢索查詢: '自然語言處理技術...' (top_k=10)\n",
      "檢索完成，找到 10 個相關結果\n",
      "找到 10 個相關結果:\n",
      "1. 分數: 0.9469\n",
      "   來源: test_ml_chunks/prod_test_ml_path_merged_node_58_chunk_0_to_node_60_chunk_0.txt\n",
      "   內容: Chunk path: ./chunks_output/test_ml_chunks/prod_test_ml_path_merged_node_58_chunk_0_to_node_60_chunk...\n",
      "\n",
      "2. 分數: 1.0545\n",
      "   來源: test_ml_chunks/prod_test_ml_path_merged_node_38_chunk_0_to_node_40_chunk_0.txt\n",
      "   內容: Chunk path: ./chunks_output/test_ml_chunks/prod_test_ml_path_merged_node_38_chunk_0_to_node_40_chunk...\n",
      "\n",
      "3. 分數: 1.0747\n",
      "   來源: documents_dup_part_1_part_1_chunks/prod_documents_dup_part_1_part_1_path_merged_node_0_chunk_24_to_node_0_chunk_24.txt\n",
      "   內容: Chunk path: ./chunks_output/documents_dup_part_1_part_1_chunks/prod_documents_dup_part_1_part_1_path...\n",
      "\n",
      "4. 分數: 1.1020\n",
      "   來源: test_ml_chunks/prod_test_ml_node_27_chunk_0.txt\n",
      "   內容: Chunk path: ./chunks_output/test_ml_chunks/prod_test_ml_node_27_chunk_0.txt\n",
      "Chunk name: prod_test_ml...\n",
      "\n",
      "5. 分數: 1.1128\n",
      "   來源: test_ml_chunks/prod_test_ml_node_66_chunk_0.txt\n",
      "   內容: Chunk path: ./chunks_output/test_ml_chunks/prod_test_ml_node_66_chunk_0.txt\n",
      "Chunk name: prod_test_ml...\n",
      "\n",
      "\n",
      "============================================================\n",
      "測試批量檢索:\n",
      "處理查詢 1/2\n",
      "正在檢索查詢: '人工智能的發展趨勢...' (top_k=5)\n",
      "檢索完成，找到 5 個相關結果\n",
      "處理查詢 2/2\n",
      "正在檢索查詢: '機器學習算法...' (top_k=5)\n",
      "檢索完成，找到 5 個相關結果\n",
      "查詢 1: 找到 5 個結果\n",
      "查詢 2: 找到 5 個結果\n",
      "RAG檢索器已關閉\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from pymilvus import MilvusClient, DataType, CollectionSchema, FieldSchema\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import json\n",
    "from datetime import datetime\n",
    "import torch\n",
    "\n",
    "\n",
    "class MilvusLiteRAGRetriever:\n",
    "    def __init__(self, db_path=\"./milvus_data.db\", model_path=\"./embedding-model\"):\n",
    "        self.db_path = db_path\n",
    "        \n",
    "        # 加載模型到對應設備\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        print(f\"RAG檢索器使用設備: {self.device}\")\n",
    "        self.model = SentenceTransformer(model_path).to(self.device)\n",
    "        self.dimension = 768\n",
    "        \n",
    "        self.client = MilvusClient(db_path)\n",
    "        self.collection_name = \"testchunks\"\n",
    "        self.vector_field_name = \"vector\"\n",
    "        \n",
    "        # 檢查集合是否存在\n",
    "        collections = self.client.list_collections()\n",
    "        if self.collection_name not in collections:\n",
    "            raise ValueError(f\"集合 '{self.collection_name}' 不存在！請先運行數據插入程序。\")\n",
    "        \n",
    "        print(f\"RAG檢索器初始化完成，連接到集合: {self.collection_name}\")\n",
    "    \n",
    "    def retrieve_for_rag(self, query_text, top_k=10, score_threshold=None, filter_condition=None):\n",
    "        \"\"\"\n",
    "        為 RAG 系統檢索相關文檔\n",
    "        \n",
    "        Args:\n",
    "            query_text (str): 查詢文本\n",
    "            top_k (int): 返回的結果數量，默認10\n",
    "            score_threshold (float, optional): 分數閾值，低於此分數的結果將被過濾\n",
    "            filter_condition (str, optional): 過濾條件，例如 'folder == \"某個文件夾\"'\n",
    "        \n",
    "        Returns:\n",
    "            dict: 包含檢索結果的字典\n",
    "                - hits: 檢索到的文檔列表\n",
    "                - scores: 對應的相似度分數列表\n",
    "                - query: 原始查詢文本\n",
    "                - total_hits: 總命中數\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print(f\"正在檢索查詢: '{query_text[:50]}...' (top_k={top_k})\")\n",
    "            \n",
    "            # 生成查詢嵌入向量\n",
    "            with torch.no_grad():\n",
    "                query_embedding = self.model.encode(\n",
    "                    [query_text], \n",
    "                    device=self.device,\n",
    "                    convert_to_numpy=True,\n",
    "                    show_progress_bar=False\n",
    "                )[0].tolist()\n",
    "            \n",
    "            # FLAT 索引搜尋參數\n",
    "            search_params = {\n",
    "                \"params\": {}\n",
    "            }\n",
    "            \n",
    "            # 執行向量搜索\n",
    "            search_results = self.client.search(\n",
    "                collection_name=self.collection_name,\n",
    "                anns_field=self.vector_field_name,\n",
    "                data=[query_embedding],\n",
    "                filter=filter_condition,\n",
    "                limit=top_k,\n",
    "                output_fields=[\"text\", \"folder\", \"file\", \"timestamp\"],\n",
    "                search_params=search_params\n",
    "            )\n",
    "            \n",
    "            # 處理搜索結果\n",
    "            hits = []\n",
    "            scores = []\n",
    "            \n",
    "            for hit in search_results[0]:\n",
    "                score = hit[\"distance\"]  # L2距離，越小越相似\n",
    "                \n",
    "                # 如果設置了分數閾值，過濾低分結果\n",
    "                if score_threshold is not None and score > score_threshold:\n",
    "                    continue\n",
    "                \n",
    "                # 構建結果項\n",
    "                hit_item = {\n",
    "                    \"id\": hit[\"id\"],\n",
    "                    \"text\": hit[\"entity\"][\"text\"],\n",
    "                    \"source\": f\"{hit['entity']['folder']}/{hit['entity']['file']}\",\n",
    "                    \"folder\": hit[\"entity\"][\"folder\"],\n",
    "                    \"file\": hit[\"entity\"][\"file\"],\n",
    "                    \"timestamp\": hit[\"entity\"][\"timestamp\"],\n",
    "                    \"score\": score\n",
    "                }\n",
    "                \n",
    "                hits.append(hit_item)\n",
    "                scores.append(score)\n",
    "            \n",
    "            # 構建返回結果\n",
    "            result = {\n",
    "                \"hits\": hits,\n",
    "                \"scores\": scores,\n",
    "                \"query\": query_text,\n",
    "                \"total_hits\": len(hits),\n",
    "                \"top_k_requested\": top_k\n",
    "            }\n",
    "            \n",
    "            print(f\"檢索完成，找到 {len(hits)} 個相關結果\")\n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"檢索過程中發生錯誤: {e}\")\n",
    "            return {\n",
    "                \"hits\": [],\n",
    "                \"scores\": [],\n",
    "                \"query\": query_text,\n",
    "                \"total_hits\": 0,\n",
    "                \"top_k_requested\": top_k,\n",
    "                \"error\": str(e)\n",
    "            }\n",
    "    \n",
    "    def batch_retrieve(self, queries, top_k=10, score_threshold=None):\n",
    "        \"\"\"\n",
    "        批量檢索多個查詢\n",
    "        \n",
    "        Args:\n",
    "            queries (list): 查詢文本列表\n",
    "            top_k (int): 每個查詢返回的結果數量\n",
    "            score_threshold (float, optional): 分數閾值\n",
    "        \n",
    "        Returns:\n",
    "            list: 每個查詢的檢索結果列表\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        for i, query in enumerate(queries):\n",
    "            print(f\"處理查詢 {i+1}/{len(queries)}\")\n",
    "            result = self.retrieve_for_rag(query, top_k, score_threshold)\n",
    "            results.append(result)\n",
    "        return results\n",
    "    \n",
    "    def get_retriever_stats(self):\n",
    "        \"\"\"獲取檢索器統計信息\"\"\"\n",
    "        try:\n",
    "            stats = self.client.get_collection_stats(self.collection_name)\n",
    "            return {\n",
    "                \"collection_name\": self.collection_name,\n",
    "                \"stats\": stats,\n",
    "                \"device\": self.device,\n",
    "                \"model_dimension\": self.dimension\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\"error\": str(e)}\n",
    "    \n",
    "    def close(self):\n",
    "        \"\"\"關閉檢索器\"\"\"\n",
    "        self.client.close()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        print(\"RAG檢索器已關閉\")\n",
    "\n",
    "\n",
    "# 使用示例和測試函數\n",
    "def test_rag_retriever():\n",
    "    \"\"\"測試 RAG 檢索器\"\"\"\n",
    "    try:\n",
    "        # 初始化檢索器\n",
    "        retriever = MilvusLiteRAGRetriever(\"./milvus_data.db\", \"./embedding-model\")\n",
    "        \n",
    "        # 獲取統計信息\n",
    "        stats = retriever.get_retriever_stats()\n",
    "        print(f\"檢索器統計: {stats}\")\n",
    "        \n",
    "        # 測試單個查詢\n",
    "        test_queries = [\n",
    "            \"人工智能的發展趨勢\",\n",
    "            \"機器學習算法\",\n",
    "            \"深度學習應用\",\n",
    "            \"自然語言處理技術\"\n",
    "        ]\n",
    "        \n",
    "        for query in test_queries:\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"測試查詢: {query}\")\n",
    "            \n",
    "            # 執行檢索\n",
    "            result = retriever.retrieve_for_rag(query, top_k=10)\n",
    "            \n",
    "            if result[\"total_hits\"] > 0:\n",
    "                print(f\"找到 {result['total_hits']} 個相關結果:\")\n",
    "                for i, hit in enumerate(result[\"hits\"][:5], 1):  # 只顯示前5個\n",
    "                    print(f\"{i}. 分數: {hit['score']:.4f}\")\n",
    "                    print(f\"   來源: {hit['source']}\")\n",
    "                    print(f\"   內容: {hit['text'][:100]}...\")\n",
    "                    print()\n",
    "            else:\n",
    "                print(\"未找到相關結果\")\n",
    "        \n",
    "        # 測試批量檢索\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"測試批量檢索:\")\n",
    "        batch_results = retriever.batch_retrieve(test_queries[:2], top_k=5)\n",
    "        for i, result in enumerate(batch_results):\n",
    "            print(f\"查詢 {i+1}: 找到 {result['total_hits']} 個結果\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"測試過程中發生錯誤: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    finally:\n",
    "        if 'retriever' in locals():\n",
    "            retriever.close()\n",
    "\n",
    "\n",
    "# 簡化的 RAG 檢索函數（可直接導入使用）\n",
    "def rag_retrieve(query_text, top_k=10, db_path=\"./milvus_data.db\", model_path=\"./embedding-model\"):\n",
    "    \"\"\"\n",
    "    簡化的 RAG 檢索函數，可以直接導入使用\n",
    "    \n",
    "    Args:\n",
    "        query_text (str): 查詢文本\n",
    "        top_k (int): 返回結果數量\n",
    "        db_path (str): Milvus 數據庫路徑\n",
    "        model_path (str): 嵌入模型路徑\n",
    "    \n",
    "    Returns:\n",
    "        dict: 檢索結果\n",
    "    \"\"\"\n",
    "    retriever = None\n",
    "    try:\n",
    "        retriever = MilvusLiteRAGRetriever(db_path, model_path)\n",
    "        result = retriever.retrieve_for_rag(query_text, top_k)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"hits\": [],\n",
    "            \"scores\": [],\n",
    "            \"query\": query_text,\n",
    "            \"total_hits\": 0,\n",
    "            \"error\": str(e)\n",
    "        }\n",
    "    finally:\n",
    "        if retriever:\n",
    "            retriever.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 運行測試\n",
    "    test_rag_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38944cd-07e8-4668-a22a-8842cf083517",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.exceptions import RequestError, ConnectionError\n",
    "\n",
    "class ElasticsearchSearcher:\n",
    "    def __init__(self, \n",
    "                 es_url=\"https://localhost:9200\", \n",
    "                 username=\"elastic\", \n",
    "                 password=\"\", \n",
    "                 index_name=\"chunk_documents\"):\n",
    "        \"\"\"\n",
    "        初始化搜索器\n",
    "        :param es_url: Elasticsearch 地址\n",
    "        :param username: 用户名（默认 elastic）\n",
    "        :param password: 密码\n",
    "        :param index_name: 要搜索的索引名（默认与导入时一致）\n",
    "        \"\"\"\n",
    "        self.es_url = es_url\n",
    "        self.username = username\n",
    "        self.password = password\n",
    "        self.index_name = index_name\n",
    "        self.es = self._connect()\n",
    "\n",
    "    def _connect(self):\n",
    "        \"\"\"建立与 Elasticsearch 的连接\"\"\"\n",
    "        try:\n",
    "            es = Elasticsearch(\n",
    "                [self.es_url],\n",
    "                basic_auth=(self.username, self.password),\n",
    "                verify_certs=False,  # 保持与之前一致的 SSL 配置\n",
    "                ssl_show_warn=False\n",
    "            )\n",
    "            # 验证连接\n",
    "            if es.ping():\n",
    "                print(f\"✅ 已连接到 Elasticsearch：{self.es_url}\")\n",
    "                return es\n",
    "            else:\n",
    "                print(\"❌ 连接失败：Elasticsearch 未响应\")\n",
    "                return None\n",
    "        except ConnectionError:\n",
    "            print(f\"❌ 无法连接到 {self.es_url}，请检查服务是否启动\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 连接错误：{e}\")\n",
    "            return None\n",
    "\n",
    "    def search(self, keyword, size=10, preview_length=200):\n",
    "        \"\"\"\n",
    "        搜索包含关键词的文档\n",
    "        :param keyword: 搜索关键词（字符串）\n",
    "        :param size: 返回结果数量（默认10条）\n",
    "        :param preview_length: 内容预览长度（默认200字符）\n",
    "        :return: 格式化的搜索结果列表\n",
    "        \"\"\"\n",
    "        if not self.es:\n",
    "            print(\"⚠️ 未建立有效连接，请检查配置\")\n",
    "            return []\n",
    "\n",
    "        try:\n",
    "            # 构造搜索查询（在 content 字段中搜索关键词）\n",
    "            query = {\n",
    "                \"query\": {\n",
    "                    \"match\": {\n",
    "                        \"content\": keyword  # 搜索内容字段\n",
    "                    }\n",
    "                },\n",
    "                \"size\": size\n",
    "            }\n",
    "\n",
    "            # 执行搜索\n",
    "            response = self.es.search(index=self.index_name, body=query)\n",
    "            hits = response[\"hits\"][\"hits\"]\n",
    "            total = response[\"hits\"][\"total\"][\"value\"]\n",
    "\n",
    "            print(f\"\\n🔍 搜索关键词：'{keyword}'，找到 {total} 条匹配结果（显示前 {len(hits)} 条）\")\n",
    "\n",
    "            # 格式化结果\n",
    "            results = []\n",
    "            for hit in hits:\n",
    "                source = hit[\"_source\"]\n",
    "                results.append({\n",
    "                    \"id\": hit[\"_id\"],\n",
    "                    \"filename\": source[\"filename\"],\n",
    "                    \"folder\": source[\"folder\"],\n",
    "                    \"score\": hit[\"_score\"],  # 匹配得分（越高越相关）\n",
    "                    \"content_preview\": source[\"content\"][:preview_length] + \"...\" if len(source[\"content\"]) > preview_length else source[\"content\"],\n",
    "                    \"import_time\": source[\"import_time\"]\n",
    "                })\n",
    "\n",
    "            return results\n",
    "\n",
    "        except RequestError as e:\n",
    "            print(f\"❌ 搜索请求错误：{e}\")\n",
    "            return []\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 搜索失败：{e}\")\n",
    "            return []\n",
    "\n",
    "    def print_results(self, results):\n",
    "        \"\"\"格式化打印搜索结果\"\"\"\n",
    "        for i, result in enumerate(results, 1):\n",
    "            print(f\"\\n--- 结果 {i} ---\")\n",
    "            print(f\"文件名：{result['filename']}\")\n",
    "            print(f\"文件夹：{result['folder']}\")\n",
    "            print(f\"相关度：{result['score']:.2f}\")\n",
    "            print(f\"内容预览：{result['content_preview']}\")\n",
    "            print(f\"导入时间：{result['import_time']}\")\n",
    "\n",
    "\n",
    "# 示例用法\n",
    "if __name__ == \"__main__\":\n",
    "    # 初始化搜索器（替换为你的密码）\n",
    "    searcher = ElasticsearchSearcher(\n",
    "        password=\"vSCQnhBXoox0sRo7-U1x\",  # 你的 Elasticsearch 密码\n",
    "        index_name=\"chunk_documents\"       # 与导入时的索引名一致\n",
    "    )\n",
    "\n",
    "    # 搜索示例（替换为你想搜索的关键词）\n",
    "    keyword = \"人工智能\"  # 例如 \"人工智能\"、\"数据分析\" 等\n",
    "    search_results = searcher.search(keyword, size=5)  # 搜索并返回前5条结果\n",
    "\n",
    "    # 打印结果\n",
    "    searcher.print_results(search_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1577f12a-744b-4a55-8296-8a2955b6d70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:使用设备: cuda | 最大序列长度: 4096\n",
      "INFO:__main__:BCE嵌入模型加载成功: ./embedding-model\n",
      "INFO:__main__:BCE重排序模型加载成功: ./reranker-model\n",
      "INFO:__main__:Milvus 连接成功: testchunks\n",
      "INFO:elastic_transport.transport:HEAD https://localhost:9200/ [status:200 duration:0.015s]\n",
      "INFO:__main__:Elasticsearch 连接成功: https://localhost:9200\n",
      "INFO:__main__:混合检索系统初始化完成\n",
      "INFO:__main__:开始混合检索: '人工智能的发展趋势...'\n",
      "INFO:__main__:向量搜索找到 50 个结果\n",
      "INFO:elastic_transport.transport:POST https://localhost:9200/chunk_documents/_search [status:200 duration:0.018s]\n",
      "INFO:__main__:关键词搜索找到 50 个结果\n",
      "INFO:__main__:合并后共有 6 个唯一结果\n",
      "ERROR:__main__:重排序失败: The expanded size of the tensor (2962) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [6, 2962].  Tensor sizes: [1, 514]\n",
      "INFO:__main__:混合检索完成，找到 5 个结果，耗时 0.07 秒\n",
      "INFO:__main__:开始混合检索: '人工智能的发展趋势...'\n",
      "INFO:__main__:向量搜索找到 50 个结果\n",
      "INFO:elastic_transport.transport:POST https://localhost:9200/chunk_documents/_search [status:200 duration:0.012s]\n",
      "INFO:__main__:关键词搜索找到 50 个结果\n",
      "INFO:__main__:合并后共有 6 个唯一结果\n",
      "INFO:__main__:混合检索完成，找到 3 个结果，耗时 0.04 秒\n",
      "INFO:__main__:开始混合检索: '机器学习算法原理...'\n",
      "INFO:__main__:向量搜索找到 50 个结果\n",
      "INFO:elastic_transport.transport:POST https://localhost:9200/chunk_documents/_search [status:200 duration:0.010s]\n",
      "INFO:__main__:关键词搜索找到 50 个结果\n",
      "INFO:__main__:合并后共有 28 个唯一结果\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "测试查询: 人工智能的发展趋势\n",
      "\n",
      "【启用重排序】\n",
      "\n",
      "================================================================================\n",
      "查询: 人工智能的发展趋势\n",
      "执行时间: 0.07 秒\n",
      "向量搜索结果: 50 个\n",
      "关键词搜索结果: 50 个\n",
      "合并后结果: 6 个\n",
      "最终返回: 5 个\n",
      "重排序: 已启用\n",
      "================================================================================\n",
      "\n",
      "--- 结果 1 ---\n",
      "来源: documents_dup_part_1_part_1_chunks/prod_documents_dup_part_1_part_1_path_merged_node_0_chunk_92_to_node_0_chunk_92.txt\n",
      "搜索类型: vector\n",
      "分数: 0.5393\n",
      "内容: Chunk path: ./chunks_output/documents_dup_part_1_part_1_chunks/prod_documents_dup_part_1_part_1_path_merged_node_0_chunk_92_to_node_0_chunk_92.txt\n",
      "Chunk name: prod_documents_dup_part_1_part_1_path_merged_node_0_chunk_92_to_node_0_chunk_92.txt\n",
      "==================================================\n",
      "Chunk ...\n",
      "\n",
      "--- 结果 2 ---\n",
      "来源: test_ml_chunks/prod_test_ml_node_80_chunk_0.txt\n",
      "搜索类型: vector\n",
      "分数: 0.4966\n",
      "内容: Chunk path: ./chunks_output/test_ml_chunks/prod_test_ml_node_80_chunk_0.txt\n",
      "Chunk name: prod_test_ml_node_80_chunk_0.txt\n",
      "==================================================\n",
      "Chunk ID: node_80_chunk_0\n",
      "Source Node: 80\n",
      "Chunk Index: 0\n",
      "Path Titles: AI 与其他学科融合：与物理学（如量子机器学习，提升计算速度）、生物学（如生物信息学中的基因序列分析）、社会学（如社...\n",
      "\n",
      "--- 结果 3 ---\n",
      "来源: test_ml_chunks/prod_test_ml_path_merged_node_76_chunk_0_to_node_79_chunk_0.txt\n",
      "搜索类型: vector\n",
      "分数: 0.4914\n",
      "内容: Chunk path: ./chunks_output/test_ml_chunks/prod_test_ml_path_merged_node_76_chunk_0_to_node_79_chunk_0.txt\n",
      "Chunk name: prod_test_ml_path_merged_node_76_chunk_0_to_node_79_chunk_0.txt\n",
      "==================================================\n",
      "Chunk ID: path_merged_node_76_chunk_0_to_node_79_chunk_0\n",
      "Source No...\n",
      "\n",
      "--- 结果 4 ---\n",
      "来源: test_ml_chunks/prod_test_ml_node_82_chunk_0.txt\n",
      "搜索类型: vector\n",
      "分数: 0.4876\n",
      "内容: Chunk path: ./chunks_output/test_ml_chunks/prod_test_ml_node_82_chunk_0.txt\n",
      "Chunk name: prod_test_ml_node_82_chunk_0.txt\n",
      "==================================================\n",
      "Chunk ID: node_82_chunk_0\n",
      "Source Node: 82\n",
      "Chunk Index: 0\n",
      "Path Titles: 6. 总结\n",
      "==================================================\n",
      "6...\n",
      "\n",
      "--- 结果 5 ---\n",
      "来源: test_ml_chunks/prod_test_ml_path_merged_node_71_chunk_0_to_node_74_chunk_0.txt\n",
      "搜索类型: vector\n",
      "分数: 0.4846\n",
      "内容: Chunk path: ./chunks_output/test_ml_chunks/prod_test_ml_path_merged_node_71_chunk_0_to_node_74_chunk_0.txt\n",
      "Chunk name: prod_test_ml_path_merged_node_71_chunk_0_to_node_74_chunk_0.txt\n",
      "==================================================\n",
      "Chunk ID: path_merged_node_71_chunk_0_to_node_74_chunk_0\n",
      "Source No...\n",
      "\n",
      "【禁用重排序】\n",
      "1. 混合分数: 0.3236 | 来源: documents_dup_part_1_part_1_chunks/prod_documents_dup_part_1_part_1_path_merged_node_0_chunk_92_to_node_0_chunk_92.txt\n",
      "2. 混合分数: 0.2979 | 来源: test_ml_chunks/prod_test_ml_node_80_chunk_0.txt\n",
      "3. 混合分数: 0.2948 | 来源: test_ml_chunks/prod_test_ml_path_merged_node_76_chunk_0_to_node_79_chunk_0.txt\n",
      "\n",
      "====================================================================================================\n",
      "测试查询: 机器学习算法原理\n",
      "\n",
      "【启用重排序】\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:__main__:重排序失败: The expanded size of the tensor (3380) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [28, 3380].  Tensor sizes: [1, 514]\n",
      "INFO:__main__:混合检索完成，找到 5 个结果，耗时 0.11 秒\n",
      "INFO:__main__:开始混合检索: '机器学习算法原理...'\n",
      "INFO:__main__:向量搜索找到 50 个结果\n",
      "INFO:elastic_transport.transport:POST https://localhost:9200/chunk_documents/_search [status:200 duration:0.016s]\n",
      "INFO:__main__:关键词搜索找到 50 个结果\n",
      "INFO:__main__:合并后共有 28 个唯一结果\n",
      "INFO:__main__:混合检索完成，找到 3 个结果，耗时 0.04 秒\n",
      "INFO:__main__:使用设备: cuda | 最大序列长度: 4096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "查询: 机器学习算法原理\n",
      "执行时间: 0.11 秒\n",
      "向量搜索结果: 50 个\n",
      "关键词搜索结果: 50 个\n",
      "合并后结果: 28 个\n",
      "最终返回: 5 个\n",
      "重排序: 已启用\n",
      "================================================================================\n",
      "\n",
      "--- 结果 1 ---\n",
      "来源: test_ml_chunks/prod_test_ml_path_merged_node_11_chunk_0_to_node_15_chunk_0.txt\n",
      "搜索类型: vector\n",
      "分数: 0.6455\n",
      "内容: Chunk path: ./chunks_output/test_ml_chunks/prod_test_ml_path_merged_node_11_chunk_0_to_node_15_chunk_0.txt\n",
      "Chunk name: prod_test_ml_path_merged_node_11_chunk_0_to_node_15_chunk_0.txt\n",
      "==================================================\n",
      "Chunk ID: path_merged_node_11_chunk_0_to_node_15_chunk_0\n",
      "Source No...\n",
      "\n",
      "--- 结果 2 ---\n",
      "来源: test_ml_chunks/prod_test_ml_node_26_chunk_0.txt\n",
      "搜索类型: vector\n",
      "分数: 0.5994\n",
      "内容: Chunk path: ./chunks_output/test_ml_chunks/prod_test_ml_node_26_chunk_0.txt\n",
      "Chunk name: prod_test_ml_node_26_chunk_0.txt\n",
      "==================================================\n",
      "Chunk ID: node_26_chunk_0\n",
      "Source Node: 26\n",
      "Chunk Index: 0\n",
      "Path Titles: 3. 机器学习的主要分类 > 3.1 监督学习（Supervised Learning） > 3.1.1 定义与特点...\n",
      "\n",
      "--- 结果 3 ---\n",
      "来源: test_ml_chunks/prod_test_ml_node_27_chunk_0.txt\n",
      "搜索类型: vector\n",
      "分数: 0.5955\n",
      "内容: Chunk path: ./chunks_output/test_ml_chunks/prod_test_ml_node_27_chunk_0.txt\n",
      "Chunk name: prod_test_ml_node_27_chunk_0.txt\n",
      "==================================================\n",
      "Chunk ID: node_27_chunk_0\n",
      "Source Node: 27\n",
      "Chunk Index: 0\n",
      "Path Titles: 3. 机器学习的主要分类 > 3.1 监督学习（Supervised Learning） > 3.1.2 常见任务与...\n",
      "\n",
      "--- 结果 4 ---\n",
      "来源: test_ml_chunks/prod_test_ml_node_23_chunk_0.txt\n",
      "搜索类型: vector\n",
      "分数: 0.5904\n",
      "内容: Chunk path: ./chunks_output/test_ml_chunks/prod_test_ml_node_23_chunk_0.txt\n",
      "Chunk name: prod_test_ml_node_23_chunk_0.txt\n",
      "==================================================\n",
      "Chunk ID: node_23_chunk_0\n",
      "Source Node: 23\n",
      "Chunk Index: 0\n",
      "Path Titles: 3. 机器学习的主要分类\n",
      "=============================================...\n",
      "\n",
      "--- 结果 5 ---\n",
      "来源: test_ml_chunks/prod_test_ml_node_3_chunk_0.txt\n",
      "搜索类型: vector\n",
      "分数: 0.5871\n",
      "内容: Chunk path: ./chunks_output/test_ml_chunks/prod_test_ml_node_3_chunk_0.txt\n",
      "Chunk name: prod_test_ml_node_3_chunk_0.txt\n",
      "==================================================\n",
      "Chunk ID: node_3_chunk_0\n",
      "Source Node: 3\n",
      "Chunk Index: 0\n",
      "Path Titles: 1. 引言 > 1.1 机器学习的定义\n",
      "==========================================...\n",
      "\n",
      "【禁用重排序】\n",
      "1. 混合分数: 0.3873 | 来源: test_ml_chunks/prod_test_ml_path_merged_node_11_chunk_0_to_node_15_chunk_0.txt\n",
      "2. 混合分数: 0.3596 | 来源: test_ml_chunks/prod_test_ml_node_26_chunk_0.txt\n",
      "3. 混合分数: 0.3573 | 来源: test_ml_chunks/prod_test_ml_node_27_chunk_0.txt\n",
      "\n",
      "====================================================================================================\n",
      "测试独立搜索函数:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:BCE嵌入模型加载成功: ./embedding-model\n",
      "INFO:__main__:BCE重排序模型加载成功: ./reranker-model\n",
      "INFO:__main__:Milvus 连接成功: testchunks\n",
      "INFO:elastic_transport.transport:HEAD https://localhost:9200/ [status:200 duration:0.015s]\n",
      "INFO:__main__:Elasticsearch 连接成功: https://localhost:9200\n",
      "INFO:__main__:混合检索系统初始化完成\n",
      "INFO:__main__:开始混合检索: '人工智能技术应用场景...'\n",
      "INFO:__main__:向量搜索找到 50 个结果\n",
      "INFO:elastic_transport.transport:POST https://localhost:9200/chunk_documents/_search [status:200 duration:0.017s]\n",
      "INFO:__main__:关键词搜索找到 50 个结果\n",
      "INFO:__main__:合并后共有 13 个唯一结果\n",
      "ERROR:__main__:重排序失败: The expanded size of the tensor (2963) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [13, 2963].  Tensor sizes: [1, 514]\n",
      "INFO:__main__:混合检索完成，找到 3 个结果，耗时 0.07 秒\n",
      "INFO:__main__:GPU缓存已清理\n",
      "INFO:__main__:混合检索系统已关闭\n",
      "INFO:__main__:GPU缓存已清理\n",
      "INFO:__main__:混合检索系统已关闭\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "独立函数搜索结果: 找到 3 个结果\n",
      "1. 分数: 0.5325 | 来源: documents_dup_part_1_part_1_chunks/prod_documents_dup_part_1_part_1_path_merged_node_0_chunk_92_to_node_0_chunk_92.txt\n",
      "2. 分数: 0.5137 | 来源: test_ml_chunks/prod_test_ml_node_66_chunk_0.txt\n",
      "3. 分数: 0.5115 | 来源: test_ml_chunks/prod_test_ml_node_80_chunk_0.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from typing import List, Dict, Any, Optional, Union\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from pymilvus import MilvusClient\n",
    "from elasticsearch import Elasticsearch\n",
    "import json\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "# 配置日志\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class HybridRAGSearcher:\n",
    "    \"\"\"\n",
    "    混合检索与重排序系统\n",
    "    结合 Milvus 向量搜索、Elasticsearch 关键词搜索，基于 transformers 加载 BCE 系列模型\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 milvus_db_path=\"./milvus_data.db\",\n",
    "                 embedding_model_name_or_path=\"maidalun1020/bce-embedding-base_v1\",\n",
    "                 reranker_model_name_or_path=\"maidalun1020/bce-reranker-base_v1\",\n",
    "                 es_url=\"https://localhost:9200\",\n",
    "                 es_username=\"elastic\",\n",
    "                 es_password=\"\",\n",
    "                 es_index_name=\"chunk_documents\",\n",
    "                 milvus_collection_name=\"testchunks\",\n",
    "                 max_seq_length: int = 512):\n",
    "        \"\"\"初始化混合检索系统\"\"\"\n",
    "        \n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.max_seq_length = max_seq_length\n",
    "        logger.info(f\"使用设备: {self.device} | 最大序列长度: {self.max_seq_length}\")\n",
    "        \n",
    "        # 初始化模型\n",
    "        self.embedding_tokenizer, self.embedding_model = self._init_embedding_model(embedding_model_name_or_path)\n",
    "        self.reranker_tokenizer, self.reranker_model = self._init_reranker_model(reranker_model_name_or_path)\n",
    "        \n",
    "        # 初始化 Milvus\n",
    "        self._init_milvus(milvus_db_path, milvus_collection_name)\n",
    "        \n",
    "        # 初始化 Elasticsearch\n",
    "        self._init_elasticsearch(es_url, es_username, es_password, es_index_name)\n",
    "        \n",
    "        logger.info(\"混合检索系统初始化完成\")\n",
    "    \n",
    "    def _init_embedding_model(self, model_name_or_path: str):\n",
    "        \"\"\"初始化 BCE 嵌入模型\"\"\"\n",
    "        try:\n",
    "            tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "            model = AutoModel.from_pretrained(model_name_or_path)\n",
    "            model = model.to(self.device)\n",
    "            model.eval()\n",
    "            logger.info(f\"BCE嵌入模型加载成功: {model_name_or_path}\")\n",
    "            return tokenizer, model\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"嵌入模型加载失败: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def _init_reranker_model(self, model_name_or_path: str):\n",
    "        \"\"\"初始化 BCE 重排序模型\"\"\"\n",
    "        try:\n",
    "            tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "            model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path)\n",
    "            model = model.to(self.device)\n",
    "            model.eval()\n",
    "            logger.info(f\"BCE重排序模型加载成功: {model_name_or_path}\")\n",
    "            return tokenizer, model\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"重排序模型加载失败: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def _init_milvus(self, db_path, collection_name):\n",
    "        \"\"\"初始化 Milvus 连接\"\"\"\n",
    "        try:\n",
    "            self.milvus_client = MilvusClient(db_path)\n",
    "            self.milvus_collection_name = collection_name\n",
    "            \n",
    "            collections = self.milvus_client.list_collections()\n",
    "            if collection_name not in collections:\n",
    "                raise ValueError(f\"Milvus 集合 '{collection_name}' 不存在\")\n",
    "            \n",
    "            logger.info(f\"Milvus 连接成功: {collection_name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Milvus 初始化失败: {e}\")\n",
    "            self.milvus_client = None\n",
    "    \n",
    "    def _init_elasticsearch(self, es_url, username, password, index_name):\n",
    "        \"\"\"初始化 Elasticsearch 连接\"\"\"\n",
    "        try:\n",
    "            self.es_client = Elasticsearch(\n",
    "                [es_url],\n",
    "                basic_auth=(username, password),\n",
    "                verify_certs=False,\n",
    "                ssl_show_warn=False\n",
    "            )\n",
    "            \n",
    "            self.es_index_name = index_name\n",
    "            \n",
    "            if self.es_client.ping():\n",
    "                logger.info(f\"Elasticsearch 连接成功: {es_url}\")\n",
    "            else:\n",
    "                logger.warning(\"Elasticsearch 连接失败\")\n",
    "                self.es_client = None\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Elasticsearch 初始化失败: {e}\")\n",
    "            self.es_client = None\n",
    "    \n",
    "    def _generate_embedding(self, texts: List[str]) -> np.ndarray:\n",
    "        \"\"\"生成文本嵌入\"\"\"\n",
    "        with torch.no_grad():\n",
    "            inputs = self.embedding_tokenizer(\n",
    "                texts,\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=self.max_seq_length,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            \n",
    "            inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "            outputs = self.embedding_model(** inputs)\n",
    "            cls_embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "            normalized_embeddings = cls_embeddings / cls_embeddings.norm(dim=1, keepdim=True)\n",
    "            \n",
    "            return normalized_embeddings.cpu().numpy()\n",
    "    \n",
    "    def _vector_search(self, query_text: str, top_k: int = 20) -> List[Dict]:\n",
    "        \"\"\"执行向量搜索\"\"\"\n",
    "        if not self.milvus_client:\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            query_embedding = self._generate_embedding([query_text])[0].tolist()\n",
    "            \n",
    "            search_results = self.milvus_client.search(\n",
    "                collection_name=self.milvus_collection_name,\n",
    "                anns_field=\"vector\",\n",
    "                data=[query_embedding],\n",
    "                limit=top_k,\n",
    "                output_fields=[\"text\", \"folder\", \"file\", \"timestamp\"],\n",
    "                search_params={\"params\": {}}\n",
    "            )\n",
    "            \n",
    "            results = []\n",
    "            for hit in search_results[0]:\n",
    "                results.append({\n",
    "                    \"id\": f\"milvus_{hit['id']}\",\n",
    "                    \"text\": hit[\"entity\"][\"text\"],\n",
    "                    \"source\": f\"{hit['entity']['folder']}/{hit['entity']['file']}\",\n",
    "                    \"folder\": hit[\"entity\"][\"folder\"],\n",
    "                    \"file\": hit[\"entity\"][\"file\"],\n",
    "                    \"timestamp\": hit[\"entity\"][\"timestamp\"],\n",
    "                    \"score\": 1.0 / (1.0 + hit[\"distance\"]),\n",
    "                    \"search_type\": \"vector\"\n",
    "                })\n",
    "            \n",
    "            logger.info(f\"向量搜索找到 {len(results)} 个结果\")\n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"向量搜索失败: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def _keyword_search(self, query_text: str, top_k: int = 20) -> List[Dict]:\n",
    "        \"\"\"执行关键词搜索\"\"\"\n",
    "        if not self.es_client:\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            query = {\n",
    "                \"query\": {\n",
    "                    \"match\": {\n",
    "                        \"content\": query_text\n",
    "                    }\n",
    "                },\n",
    "                \"size\": top_k\n",
    "            }\n",
    "            \n",
    "            response = self.es_client.search(index=self.es_index_name, body=query)\n",
    "            hits = response[\"hits\"][\"hits\"]\n",
    "            \n",
    "            results = []\n",
    "            for hit in hits:\n",
    "                source = hit[\"_source\"]\n",
    "                results.append({\n",
    "                    \"id\": f\"es_{hit['_id']}\",\n",
    "                    \"text\": source[\"content\"],\n",
    "                    \"source\": f\"{source['folder']}/{source['filename']}\",\n",
    "                    \"folder\": source[\"folder\"],\n",
    "                    \"file\": source[\"filename\"],\n",
    "                    \"timestamp\": source.get(\"import_time\", \"\"),\n",
    "                    \"score\": hit[\"_score\"] / 100.0,\n",
    "                    \"search_type\": \"keyword\"\n",
    "                })\n",
    "            \n",
    "            logger.info(f\"关键词搜索找到 {len(results)} 个结果\")\n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"关键词搜索失败: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def _merge_and_deduplicate(self, vector_results: List[Dict], keyword_results: List[Dict]) -> List[Dict]:\n",
    "        \"\"\"合并并去重搜索结果\"\"\"\n",
    "        seen_texts = set()\n",
    "        merged_results = []\n",
    "        \n",
    "        for result in vector_results:\n",
    "            text_key = result[\"text\"][:100]\n",
    "            if text_key not in seen_texts:\n",
    "                seen_texts.add(text_key)\n",
    "                merged_results.append(result)\n",
    "        \n",
    "        for result in keyword_results:\n",
    "            text_key = result[\"text\"][:100]\n",
    "            if text_key not in seen_texts:\n",
    "                seen_texts.add(text_key)\n",
    "                merged_results.append(result)\n",
    "        \n",
    "        logger.info(f\"合并后共有 {len(merged_results)} 个唯一结果\")\n",
    "        return merged_results\n",
    "    \n",
    "    def _calculate_rerank_scores(self, query_text: str, texts: List[str]) -> List[float]:\n",
    "        \"\"\"计算重排序分数 - 修复维度不匹配问题\"\"\"\n",
    "        with torch.no_grad():\n",
    "            # 确保文本长度不会超过模型限制\n",
    "            max_text_length = self.max_seq_length - len(self.reranker_tokenizer.tokenize(query_text)) - 3  # 预留空间给特殊标记\n",
    "            if max_text_length < 10:  # 确保有足够空间\n",
    "                max_text_length = 10\n",
    "                \n",
    "            # 处理文本，确保不会超过最大长度\n",
    "            processed_texts = []\n",
    "            for text in texts:\n",
    "                # 截断文本以适应模型长度限制\n",
    "                tokens = self.reranker_tokenizer.tokenize(text)\n",
    "                if len(tokens) > max_text_length:\n",
    "                    tokens = tokens[:max_text_length]\n",
    "                    text = self.reranker_tokenizer.convert_tokens_to_string(tokens)\n",
    "                processed_texts.append(text)\n",
    "            \n",
    "            # 构造 (query, doc) 对\n",
    "            sentence_pairs = [[query_text, doc_text] for doc_text in processed_texts]\n",
    "            \n",
    "            # Tokenize处理\n",
    "            inputs = self.reranker_tokenizer(\n",
    "                sentence_pairs,\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=self.max_seq_length,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            \n",
    "            # 移动到设备\n",
    "            inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "            \n",
    "            # 模型前向传播\n",
    "            outputs = self.reranker_model(** inputs)\n",
    "            logits = outputs.logits.view(-1,).float()\n",
    "            scores = torch.sigmoid(logits).cpu().tolist()\n",
    "            \n",
    "            return scores\n",
    "    \n",
    "    def _rerank_results(self, query_text: str, results: List[Dict], top_k: int = 10) -> List[Dict]:\n",
    "        \"\"\"使用重排序模型对结果进行重排序\"\"\"\n",
    "        if not results or not self.reranker_model:\n",
    "            return results[:top_k]\n",
    "        \n",
    "        try:\n",
    "            texts_to_rerank = [result[\"text\"] for result in results]\n",
    "            rerank_scores = self._calculate_rerank_scores(query_text, texts_to_rerank)\n",
    "            \n",
    "            for i, result in enumerate(results):\n",
    "                result[\"rerank_score\"] = rerank_scores[i]\n",
    "                result[\"original_score\"] = result[\"score\"]\n",
    "            \n",
    "            reranked_results = sorted(results, key=lambda x: x[\"rerank_score\"], reverse=True)\n",
    "            logger.info(f\"重排序完成，返回前 {min(top_k, len(reranked_results))} 个结果\")\n",
    "            return reranked_results[:top_k]\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"重排序失败: {e}\")\n",
    "            # 失败时尝试返回原始分数排序的结果\n",
    "            return sorted(results, key=lambda x: x[\"score\"], reverse=True)[:top_k]\n",
    "    \n",
    "    def hybrid_search(self, \n",
    "                     query_text: str, \n",
    "                     top_k: int = 10,\n",
    "                     vector_weight: float = 0.6,\n",
    "                     keyword_weight: float = 0.4,\n",
    "                     enable_rerank: bool = True,\n",
    "                     retrieval_size: int = 50) -> Dict[str, Any]:\n",
    "        \"\"\"执行混合检索\"\"\"\n",
    "        logger.info(f\"开始混合检索: '{query_text[:50]}...'\")\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        vector_results = self._vector_search(query_text, retrieval_size)\n",
    "        keyword_results = self._keyword_search(query_text, retrieval_size)\n",
    "        merged_results = self._merge_and_deduplicate(vector_results, keyword_results)\n",
    "        \n",
    "        if not enable_rerank:\n",
    "            for result in merged_results:\n",
    "                if result[\"search_type\"] == \"vector\":\n",
    "                    result[\"hybrid_score\"] = result[\"score\"] * vector_weight\n",
    "                else:\n",
    "                    result[\"hybrid_score\"] = result[\"score\"] * keyword_weight\n",
    "            \n",
    "            merged_results = sorted(merged_results, key=lambda x: x[\"hybrid_score\"], reverse=True)\n",
    "            final_results = merged_results[:top_k]\n",
    "        else:\n",
    "            final_results = self._rerank_results(query_text, merged_results, top_k)\n",
    "        \n",
    "        execution_time = (datetime.now() - start_time).total_seconds()\n",
    "        \n",
    "        search_result = {\n",
    "            \"query\": query_text,\n",
    "            \"results\": final_results,\n",
    "            \"total_found\": len(final_results),\n",
    "            \"vector_results_count\": len(vector_results),\n",
    "            \"keyword_results_count\": len(keyword_results),\n",
    "            \"merged_results_count\": len(merged_results),\n",
    "            \"execution_time_seconds\": execution_time,\n",
    "            \"rerank_enabled\": enable_rerank,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"error\": None  # 始终包含error键，默认为None\n",
    "        }\n",
    "        \n",
    "        logger.info(f\"混合检索完成，找到 {len(final_results)} 个结果，耗时 {execution_time:.2f} 秒\")\n",
    "        return search_result\n",
    "    \n",
    "    def print_search_results(self, search_result: Dict[str, Any], show_full_text: bool = False):\n",
    "        \"\"\"格式化打印搜索结果\"\"\"\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"查询: {search_result['query']}\")\n",
    "        print(f\"执行时间: {search_result['execution_time_seconds']:.2f} 秒\")\n",
    "        print(f\"向量搜索结果: {search_result['vector_results_count']} 个\")\n",
    "        print(f\"关键词搜索结果: {search_result['keyword_results_count']} 个\")\n",
    "        print(f\"合并后结果: {search_result['merged_results_count']} 个\")\n",
    "        print(f\"最终返回: {search_result['total_found']} 个\")\n",
    "        print(f\"重排序: {'已启用' if search_result['rerank_enabled'] else '未启用'}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        for i, result in enumerate(search_result['results'], 1):\n",
    "            print(f\"\\n--- 结果 {i} ---\")\n",
    "            print(f\"来源: {result['source']}\")\n",
    "            print(f\"搜索类型: {result['search_type']}\")\n",
    "            \n",
    "            if 'rerank_score' in result:\n",
    "                print(f\"重排序分数: {result['rerank_score']:.4f}\")\n",
    "                print(f\"原始分数: {result['original_score']:.4f}\")\n",
    "            elif 'hybrid_score' in result:\n",
    "                print(f\"混合分数: {result['hybrid_score']:.4f}\")\n",
    "            else:\n",
    "                print(f\"分数: {result['score']:.4f}\")\n",
    "            \n",
    "            text_preview = result['text'][:300] if not show_full_text else result['text']\n",
    "            if len(result['text']) > 300 and not show_full_text:\n",
    "                text_preview += \"...\"\n",
    "            print(f\"内容: {text_preview}\")\n",
    "    \n",
    "    def close(self):\n",
    "        \"\"\"关闭所有连接\"\"\"\n",
    "        if self.milvus_client:\n",
    "            self.milvus_client.close()\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            logger.info(\"GPU缓存已清理\")\n",
    "        \n",
    "        logger.info(\"混合检索系统已关闭\")\n",
    "\n",
    "\n",
    "def hybrid_rag_search(query_text: str, \n",
    "                     top_k: int = 10,\n",
    "                     milvus_db_path: str = \"./milvus_data.db\",\n",
    "                     embedding_model_name_or_path: str = \"maidalun1020/bce-embedding-base_v1\",\n",
    "                     reranker_model_name_or_path: str = \"maidalun1020/bce-reranker-base_v1\",\n",
    "                     es_url: str = \"https://localhost:9200\",\n",
    "                     es_username: str = \"elastic\",\n",
    "                     es_password: str = \"\",\n",
    "                     es_index_name: str = \"chunk_documents\",\n",
    "                     enable_rerank: bool = True,\n",
    "                     max_seq_length: int = 512) -> Dict[str, Any]:\n",
    "    \"\"\"独立的混合检索服务函数\"\"\"\n",
    "    searcher = None\n",
    "    try:\n",
    "        searcher = HybridRAGSearcher(\n",
    "            milvus_db_path=milvus_db_path,\n",
    "            embedding_model_name_or_path=embedding_model_name_or_path,\n",
    "            reranker_model_name_or_path=reranker_model_name_or_path,\n",
    "            es_url=es_url,\n",
    "            es_username=es_username,\n",
    "            es_password=es_password,\n",
    "            es_index_name=es_index_name,\n",
    "            max_seq_length=max_seq_length\n",
    "        )\n",
    "        \n",
    "        result = searcher.hybrid_search(\n",
    "            query_text=query_text,\n",
    "            top_k=top_k,\n",
    "            enable_rerank=enable_rerank\n",
    "        )\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"搜索服务错误: {e}\")\n",
    "        return {\n",
    "            \"query\": query_text,\n",
    "            \"results\": [],\n",
    "            \"total_found\": 0,\n",
    "            \"error\": str(e),\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "    \n",
    "    finally:\n",
    "        if searcher:\n",
    "            searcher.close()\n",
    "\n",
    "\n",
    "def test_hybrid_search():\n",
    "    \"\"\"测试混合检索系统\"\"\"\n",
    "    \n",
    "    config = {\n",
    "        \"milvus_db_path\": \"./milvus_data.db\",\n",
    "        \"embedding_model_name_or_path\": \"./embedding-model\",\n",
    "        \"reranker_model_name_or_path\": \"./reranker-model\",\n",
    "        \"es_url\": \"https://localhost:9200\",\n",
    "        \"es_username\": \"elastic\",\n",
    "        \"es_password\": \"vSCQnhBXoox0sRo7-U1x\",\n",
    "        \"es_index_name\": \"chunk_documents\",\n",
    "        \"max_seq_length\": 4096\n",
    "    }\n",
    "    \n",
    "    test_queries = [\n",
    "        \"人工智能的发展趋势\",\n",
    "        \"机器学习算法原理\",\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        searcher = HybridRAGSearcher(** config)\n",
    "        \n",
    "        for query in test_queries:\n",
    "            print(f\"\\n{'='*100}\")\n",
    "            print(f\"测试查询: {query}\")\n",
    "            \n",
    "            print(f\"\\n【启用重排序】\")\n",
    "            result_with_rerank = searcher.hybrid_search(\n",
    "                query_text=query,\n",
    "                top_k=5,\n",
    "                enable_rerank=True\n",
    "            )\n",
    "            searcher.print_search_results(result_with_rerank, show_full_text=False)\n",
    "            \n",
    "            print(f\"\\n【禁用重排序】\")\n",
    "            result_no_rerank = searcher.hybrid_search(\n",
    "                query_text=query,\n",
    "                top_k=3,\n",
    "                enable_rerank=False,\n",
    "                vector_weight=0.6,\n",
    "                keyword_weight=0.4\n",
    "            )\n",
    "            for i, res in enumerate(result_no_rerank['results'], 1):\n",
    "                print(f\"{i}. 混合分数: {res['hybrid_score']:.4f} | 来源: {res['source']}\")\n",
    "        \n",
    "        print(f\"\\n{'='*100}\")\n",
    "        print(\"测试独立搜索函数:\")\n",
    "        standalone_result = hybrid_rag_search(\n",
    "            query_text=\"人工智能技术应用场景\",\n",
    "            top_k=3,\n",
    "            **config\n",
    "        )\n",
    "        \n",
    "        # 修复KeyError问题：检查error键是否存在且不为None\n",
    "        if \"error\" in standalone_result and standalone_result[\"error\"] is not None:\n",
    "            print(f\"独立函数错误: {standalone_result['error']}\")\n",
    "        else:\n",
    "            print(f\"独立函数搜索结果: 找到 {standalone_result['total_found']} 个结果\")\n",
    "            for i, res in enumerate(standalone_result['results'], 1):\n",
    "                score = res.get('rerank_score', res.get('hybrid_score', res['score']))\n",
    "                print(f\"{i}. 分数: {score:.4f} | 来源: {res['source']}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"测试过程中发生错误: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    finally:\n",
    "        if 'searcher' in locals():\n",
    "            searcher.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_hybrid_search()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f7edd04-1b47-4645-8a48-9eeb5f24ab8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-19 11:38:51,405 - INFO - RAG检索系统使用设备: cuda\n",
      "2025-09-19 11:38:52,584 - INFO - BCE嵌入模型加载成功\n",
      "2025-09-19 11:38:53,817 - INFO - BCE重排序模型加载成功\n",
      "2025-09-19 11:38:53,822 - INFO - Milvus连接成功\n",
      "2025-09-19 11:38:53,870 - INFO - HEAD https://localhost:9200/ [status:200 duration:0.027s]\n",
      "2025-09-19 11:38:53,871 - INFO - Elasticsearch连接成功\n",
      "2025-09-19 11:38:53,871 - INFO - 混合RAG检索系统初始化完成\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "===== 带详细文档展示的RAG问答系统（基于DeepSeek-V3.1） =====\n",
      "说明：输入问题后，将返回AI回答+检索文档详情（含300字内容+文件路径）\n",
      "输入'退出'或'quit'可结束程序\n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "请输入你的问题： 机器学习\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-19 11:38:57,686 - INFO - 开始RAG检索，查询: 机器学习...\n",
      "2025-09-19 11:38:57,712 - INFO - POST https://localhost:9200/chunk_documents/_search [status:200 duration:0.008s]\n",
      "2025-09-19 11:38:57,747 - INFO - RAG检索完成，获取 3 条相关结果，耗时 0.06 秒\n",
      "2025-09-19 11:38:57,748 - INFO - 调用DeepSeek-V3.1生成回答...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "正在处理问题：机器学习\n",
      "步骤1/2：RAG检索相关文档...\n",
      "步骤2/2：调用大模型生成回答...\n",
      "==================================================\n",
      "\n",
      "====================================================================================================\n",
      "最终结果：\n",
      "\n",
      "# RAG问答结果\n",
      "## 一、用户问题\n",
      "机器学习\n",
      "\n",
      "## 二、AI回答\n",
      "根据提供的参考文档，以下是关于机器学习的回答：\n",
      "\n",
      "### 1. **机器学习的定义**\n",
      "机器学习（Machine Learning, ML）是人工智能（AI）的核心分支之一，通过设计算法使计算机从数据中自动学习规律、优化模型，并在未明确编程的情况下完成预测、分类或决策等任务。其核心目标是让计算机像人类一样从经验中学习，性能随数据量和训练次数的增加而提升【参考1】。\n",
      "\n",
      "### 2. **机器学习的主要分类**\n",
      "机器学习根据数据是否包含标签以及学习方式的差异，可分为三大类（具体类别未在文档中详细列出，但提到了分类依据）【参考3】。\n",
      "\n",
      "### 3. **应用与意义**\n",
      "机器学习以“数据驱动”的方式实现了从“规则编程”到“自主学习”的突破，在计算机视觉、自然语言处理、金融、医疗等领域有深远影响。尽管面临数据隐私和模型可解释性等挑战，它仍在提升智能化水平、解决复杂问题和推动产业升级中发挥重要作用，是未来数字社会的核心基础设施之一【参考2】。\n",
      "\n",
      "注：以上回答严格基于提供的参考文档，未补充额外信息。文档中未涉及机器学习的具体算法或分类细节，因此仅概括性说明。如需更详细内容，建议提供更多相关文档。\n",
      "\n",
      "## 三、检索统计信息\n",
      "- 检索到相关文档数量：3 条\n",
      "- 总检索耗时：0.06 秒（含向量检索、关键词检索、重排序）\n",
      "- 检索类型：向量检索（语义匹配）+ 关键词检索（字面匹配）\n",
      "\n",
      "## 四、### 详细检索文档（共3条）\n",
      "\n",
      "#### 文档1\n",
      "- **来源路径（相对路径）**: test_ml_chunks/prod_test_ml_node_3_chunk_0.txt\n",
      "- **完整路径（绝对路径）**: /root/doc_processor/test_ml_chunks/prod_test_ml_node_3_chunk_0.txt\n",
      "- **检索类型**: 向量检索\n",
      "- **相关性分数**: 0.5348（分数越高越相关）\n",
      "- **文档时间戳**: 2025-09-19T09:26:50.183964\n",
      "- **300字内容预览**: Chunk path: ./chunks_output/test_ml_chunks/prod_test_ml_node_3_chunk_0.txt\n",
      "Chunk name: prod_test_ml_node_3_chunk_0.txt\n",
      "==================================================\n",
      "Chunk ID: node_3_chunk_0\n",
      "Source Node: 3\n",
      "Chunk Index: 0\n",
      "Path Titles: 1. 引言 > 1.1 机器学习的定义\n",
      "==================================================\n",
      "1. 引言 > 1.1 机器学习的定义\n",
      "\n",
      "机器学习（Machine Learning, ML）是人工智能（Artificial Intelligence, AI）的核心分支之一，它通过设计算法，使计算机能够从数据中自动学习规律、优化模型，并在未明确编程的情况下完成预测、分类或决策等任务。简单来说，机器学习的核心目标是 “让计算机像人类一样从经验中学习”，其性能会随着数据量的增加和训练次数的积累而逐步提升。\n",
      "==================================================\n",
      "Metadata: {'original_text_length': 183, 'chunk_text_length': 183, 'full_content_length': 204, 'node_type': 'paragraph', 'has_tables': False, 'table_count': 0, 'is_root_content': False}\n",
      "\n",
      "--------------------------------------------------  # 分隔线，区分不同文档\n",
      "\n",
      "#### 文档2\n",
      "- **来源路径（相对路径）**: test_ml_chunks/prod_test_ml_node_82_chunk_0.txt\n",
      "- **完整路径（绝对路径）**: /root/doc_processor/test_ml_chunks/prod_test_ml_node_82_chunk_0.txt\n",
      "- **检索类型**: 关键词检索\n",
      "- **相关性分数**: 0.5230（分数越高越相关）\n",
      "- **文档时间戳**: 2025-09-19 10:23:35\n",
      "- **300字内容预览**: Chunk path: ./chunks_output/test_ml_chunks/prod_test_ml_node_82_chunk_0.txt\n",
      "Chunk name: prod_test_ml_node_82_chunk_0.txt\n",
      "==================================================\n",
      "Chunk ID: node_82_chunk_0\n",
      "Source Node: 82\n",
      "Chunk Index: 0\n",
      "Path Titles: 6. 总结\n",
      "==================================================\n",
      "6. 总结\n",
      "\n",
      "机器学习作为人工智能的核心技术，通过 “数据驱动” 的方式，实现了从 “规则编程” 到 “自主学习” 的突破，已在计算机视觉、自然语言处理、金融、医疗等领域产生深远影响。尽管当前面临数据隐私、模型可解释性等挑战，但随着技术的持续迭代，机器学习将在 “提升智能化水平”“解决复杂问题”“推动产业升级” 中发挥更重要的作用，成为未来数字社会的核心基础设施之一。对于初学者而言，理解机器学习的基本流程、分类与核心概念，是进一步深入学习和应用的关键基础。\n",
      "==================================================\n",
      "Metadata: {'original_text_length': 223, 'chunk_text_length': 223, 'full_content_length': 230, 'node_type': 'paragraph', 'has_tables': False, 'table_count': 0, 'is_root_content': False}\n",
      "\n",
      "--------------------------------------------------  # 分隔线，区分不同文档\n",
      "\n",
      "#### 文档3\n",
      "- **来源路径（相对路径）**: test_ml_chunks/prod_test_ml_node_23_chunk_0.txt\n",
      "- **完整路径（绝对路径）**: /root/doc_processor/test_ml_chunks/prod_test_ml_node_23_chunk_0.txt\n",
      "- **检索类型**: 关键词检索\n",
      "- **相关性分数**: 0.5020（分数越高越相关）\n",
      "- **文档时间戳**: 2025-09-19 10:23:35\n",
      "- **300字内容预览**: Chunk path: ./chunks_output/test_ml_chunks/prod_test_ml_node_23_chunk_0.txt\n",
      "Chunk name: prod_test_ml_node_23_chunk_0.txt\n",
      "==================================================\n",
      "Chunk ID: node_23_chunk_0\n",
      "Source Node: 23\n",
      "Chunk Index: 0\n",
      "Path Titles: 3. 机器学习的主要分类\n",
      "==================================================\n",
      "3. 机器学习的主要分类\n",
      "\n",
      "根据数据是否包含标签以及学习方式的差异，机器学习可分为三大类，各类别适用场景与核心算法不同：\n",
      "==================================================\n",
      "Metadata: {'original_text_length': 46, 'chunk_text_length': 46, 'full_content_length': 60, 'node_type': 'paragraph', 'has_tables': False, 'table_count': 0, 'is_root_content': False}\n",
      "\n",
      "--------------------------------------------------  # 分隔线，区分不同文档\n",
      "  # 插入详细文档（300字+路径）\n",
      "\n",
      "> 注：详细文档中的“完整路径（绝对路径）”可直接复制到文件管理器打开，查看文档全文。\n",
      "\n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "请输入你的问题： 退出\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-19 11:39:44,521 - INFO - RAG检索系统资源已释放\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "感谢使用，程序已退出！\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from typing import List, Dict, Any, Optional\n",
    "from transformers import AutoModel, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from pymilvus import MilvusClient\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.exceptions import RequestError, ConnectionError\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "# -------------------------- 1. 基础配置（用户可根据实际环境调整） --------------------------\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# RAG核心配置\n",
    "RAG_CONFIG = {\n",
    "    \"milvus_db_path\": \"./milvus_data.db\",\n",
    "    \"milvus_collection_name\": \"testchunks\",\n",
    "    \"embedding_model_path\": \"./embedding-model\",\n",
    "    \"reranker_model_path\": \"./reranker-model\",\n",
    "    \"es_url\": \"https://localhost:9200\",\n",
    "    \"es_username\": \"elastic\",\n",
    "    \"es_password\": \"vSCQnhBXoox0sRo7-U1x\",\n",
    "    \"es_index_name\": \"chunk_documents\",\n",
    "    \"max_seq_length\": 512,\n",
    "    \"rag_top_k\": 3,  # 检索返回的top相关结果数\n",
    "    \"doc_preview_length\": 1000  # 文档内容预览长度（固定300字）\n",
    "}\n",
    "\n",
    "# DeepSeek-V3.1大模型配置\n",
    "LLM_CONFIG = {\n",
    "    \"api_url\": \"https://api.siliconflow.cn/v1/chat/completions\",\n",
    "    \"api_key\": \"sk-ionsbeieleeekwlstqotkyrmictdzshgnbaytavcudxkixcs\",\n",
    "    \"model_name\": \"deepseek-ai/DeepSeek-V3.1\",\n",
    "    \"max_tokens\": 2000,\n",
    "    \"temperature\": 0.7,\n",
    "    \"max_retries\": 3,\n",
    "    \"retry_delay\": 5\n",
    "}\n",
    "\n",
    "# -------------------------- 2. 混合RAG检索系统（不变，复用之前稳定版本） --------------------------\n",
    "class HybridRAGSearcher:\n",
    "    def __init__(self, config: Dict[str, Any]):\n",
    "        self.config = config\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        logger.info(f\"RAG检索系统使用设备: {self.device}\")\n",
    "\n",
    "        self.embedding_tokenizer, self.embedding_model = self._init_embedding_model()\n",
    "        self.reranker_tokenizer, self.reranker_model = self._init_reranker_model()\n",
    "        self.milvus_client = self._init_milvus()\n",
    "        self.es_client = self._init_elasticsearch()\n",
    "\n",
    "        logger.info(\"混合RAG检索系统初始化完成\")\n",
    "\n",
    "    def _init_embedding_model(self):\n",
    "        try:\n",
    "            tokenizer = AutoTokenizer.from_pretrained(self.config[\"embedding_model_path\"])\n",
    "            model = AutoModel.from_pretrained(self.config[\"embedding_model_path\"]).to(self.device)\n",
    "            model.eval()\n",
    "            logger.info(\"BCE嵌入模型加载成功\")\n",
    "            return tokenizer, model\n",
    "        except Exception as e:\n",
    "            logger.error(f\"嵌入模型加载失败: {e}\")\n",
    "            raise\n",
    "\n",
    "    def _init_reranker_model(self):\n",
    "        try:\n",
    "            tokenizer = AutoTokenizer.from_pretrained(self.config[\"reranker_model_path\"])\n",
    "            model = AutoModelForSequenceClassification.from_pretrained(self.config[\"reranker_model_path\"]).to(self.device)\n",
    "            model.eval()\n",
    "            logger.info(\"BCE重排序模型加载成功\")\n",
    "            return tokenizer, model\n",
    "        except Exception as e:\n",
    "            logger.error(f\"重排序模型加载失败: {e}\")\n",
    "            raise\n",
    "\n",
    "    def _init_milvus(self):\n",
    "        try:\n",
    "            client = MilvusClient(self.config[\"milvus_db_path\"])\n",
    "            collections = client.list_collections()\n",
    "            if self.config[\"milvus_collection_name\"] not in collections:\n",
    "                raise ValueError(f\"Milvus集合 '{self.config['milvus_collection_name']}' 不存在\")\n",
    "            logger.info(\"Milvus连接成功\")\n",
    "            return client\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Milvus初始化失败: {e}\")\n",
    "            raise\n",
    "\n",
    "    def _init_elasticsearch(self):\n",
    "        try:\n",
    "            client = Elasticsearch(\n",
    "                [self.config[\"es_url\"]],\n",
    "                basic_auth=(self.config[\"es_username\"], self.config[\"es_password\"]),\n",
    "                verify_certs=False,\n",
    "                ssl_show_warn=False\n",
    "            )\n",
    "            if client.ping():\n",
    "                logger.info(\"Elasticsearch连接成功\")\n",
    "                return client\n",
    "            else:\n",
    "                raise ConnectionError(\"Elasticsearch ping失败\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Elasticsearch初始化失败: {e}\")\n",
    "            raise\n",
    "\n",
    "    def _generate_embedding(self, texts: List[str]) -> np.ndarray:\n",
    "        with torch.no_grad():\n",
    "            inputs = self.embedding_tokenizer(\n",
    "                texts, padding=True, truncation=True, max_length=self.config[\"max_seq_length\"], return_tensors=\"pt\"\n",
    "            ).to(self.device)\n",
    "            outputs = self.embedding_model(**inputs)\n",
    "            cls_emb = outputs.last_hidden_state[:, 0, :]\n",
    "            return (cls_emb / cls_emb.norm(dim=1, keepdim=True)).cpu().numpy()\n",
    "\n",
    "    def _vector_search(self, query: str) -> List[Dict]:\n",
    "        try:\n",
    "            query_emb = self._generate_embedding([query])[0].tolist()\n",
    "            results = self.milvus_client.search(\n",
    "                collection_name=self.config[\"milvus_collection_name\"],\n",
    "                anns_field=\"vector\",\n",
    "                data=[query_emb],\n",
    "                limit=self.config[\"rag_top_k\"] * 2,\n",
    "                output_fields=[\"text\", \"folder\", \"file\", \"timestamp\"]\n",
    "            )\n",
    "            return [\n",
    "                {\n",
    "                    \"id\": f\"milvus_{hit['id']}\",\n",
    "                    \"text\": hit[\"entity\"][\"text\"],\n",
    "                    \"source\": f\"{hit['entity']['folder']}/{hit['entity']['file']}\",  # 完整路径（文件夹/文件名）\n",
    "                    \"full_source_path\": os.path.abspath(f\"{hit['entity']['folder']}/{hit['entity']['file']}\"),  # 绝对路径\n",
    "                    \"score\": 1.0 / (1.0 + hit[\"distance\"]),\n",
    "                    \"search_type\": \"向量检索\",\n",
    "                    \"timestamp\": hit[\"entity\"].get(\"timestamp\", \"\")\n",
    "                }\n",
    "                for hit in results[0]\n",
    "            ]\n",
    "        except Exception as e:\n",
    "            logger.error(f\"向量搜索失败: {e}\")\n",
    "            return []\n",
    "\n",
    "    def _keyword_search(self, query: str) -> List[Dict]:\n",
    "        try:\n",
    "            response = self.es_client.search(\n",
    "                index=self.config[\"es_index_name\"],\n",
    "                body={\"query\": {\"match\": {\"content\": query}}, \"size\": self.config[\"rag_top_k\"] * 2}\n",
    "            )\n",
    "            return [\n",
    "                {\n",
    "                    \"id\": f\"es_{hit['_id']}\",\n",
    "                    \"text\": hit[\"_source\"][\"content\"],\n",
    "                    \"source\": f\"{hit['_source']['folder']}/{hit['_source']['filename']}\",  # 完整路径（文件夹/文件名）\n",
    "                    \"full_source_path\": os.path.abspath(f\"{hit['_source']['folder']}/{hit['_source']['filename']}\"),  # 绝对路径\n",
    "                    \"score\": hit[\"_score\"] / 100.0,\n",
    "                    \"search_type\": \"关键词检索\",\n",
    "                    \"timestamp\": hit[\"_source\"].get(\"import_time\", \"\")\n",
    "                }\n",
    "                for hit in response[\"hits\"][\"hits\"]\n",
    "            ]\n",
    "        except Exception as e:\n",
    "            logger.error(f\"关键词搜索失败: {e}\")\n",
    "            return []\n",
    "\n",
    "    def _merge_deduplicate(self, vector_res: List[Dict], keyword_res: List[Dict]) -> List[Dict]:\n",
    "        seen = set()\n",
    "        merged = []\n",
    "        for res in vector_res + keyword_res:\n",
    "            text_key = res[\"text\"][:100]\n",
    "            if text_key not in seen:\n",
    "                seen.add(text_key)\n",
    "                merged.append(res)\n",
    "        return sorted(merged, key=lambda x: x[\"score\"], reverse=True)[:self.config[\"rag_top_k\"] * 3]\n",
    "\n",
    "    def _rerank(self, query: str, results: List[Dict]) -> List[Dict]:\n",
    "        if not results:\n",
    "            return []\n",
    "        try:\n",
    "            max_doc_len = self.config[\"max_seq_length\"] - len(self.reranker_tokenizer.tokenize(query)) - 3\n",
    "            pairs = [[query, res[\"text\"][:max_doc_len]] for res in results]\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                inputs = self.reranker_tokenizer(\n",
    "                    pairs, padding=True, truncation=True, max_length=self.config[\"max_seq_length\"], return_tensors=\"pt\"\n",
    "                ).to(self.device)\n",
    "                scores = torch.sigmoid(self.reranker_model(**inputs).logits.view(-1,)).cpu().tolist()\n",
    "            \n",
    "            for res, score in zip(results, scores):\n",
    "                res[\"rerank_score\"] = score\n",
    "            return sorted(results, key=lambda x: x[\"rerank_score\"], reverse=True)[:self.config[\"rag_top_k\"]]\n",
    "        except Exception as e:\n",
    "            logger.error(f\"重排序失败: {e}\")\n",
    "            return sorted(results, key=lambda x: x[\"score\"], reverse=True)[:self.config[\"rag_top_k\"]]\n",
    "\n",
    "    def search(self, query: str) -> List[Dict]:\n",
    "        logger.info(f\"开始RAG检索，查询: {query[:50]}...\")\n",
    "        start = datetime.now()\n",
    "        vector_res = self._vector_search(query)\n",
    "        keyword_res = self._keyword_search(query)\n",
    "        merged_res = self._merge_deduplicate(vector_res, keyword_res)\n",
    "        final_res = self._rerank(query, merged_res)\n",
    "        \n",
    "        # 补充检索耗时（每个文档都带，便于后续展示）\n",
    "        retrieval_time = (datetime.now() - start).total_seconds()\n",
    "        for res in final_res:\n",
    "            res[\"retrieval_time\"] = retrieval_time\n",
    "        logger.info(f\"RAG检索完成，获取 {len(final_res)} 条相关结果，耗时 {retrieval_time:.2f} 秒\")\n",
    "        return final_res\n",
    "\n",
    "    def close(self):\n",
    "        if self.milvus_client:\n",
    "            self.milvus_client.close()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        logger.info(\"RAG检索系统资源已释放\")\n",
    "\n",
    "# -------------------------- 3. 新增：文档信息格式化（重点：300字内容+完整路径） --------------------------\n",
    "def format_detailed_documents(rag_results: List[Dict], preview_length: int = 300) -> str:\n",
    "    \"\"\"\n",
    "    格式化检索文档详情：包含完整路径（相对+绝对）、检索类型、分数、300字内容\n",
    "    Args:\n",
    "        rag_results: RAG检索结果列表\n",
    "        preview_length: 文档内容预览长度（默认300字）\n",
    "    Returns:\n",
    "        结构化的文档详情字符串\n",
    "    \"\"\"\n",
    "    if not rag_results:\n",
    "        return \"【未检索到相关文档】\\n\"\n",
    "    \n",
    "    detailed_str = \"### 详细检索文档（共{}条）\\n\".format(len(rag_results))\n",
    "    for idx, doc in enumerate(rag_results, 1):\n",
    "        # 1. 处理文档内容：固定截取300字，不足则全显，超过加省略号\n",
    "        doc_text = doc[\"text\"].strip()\n",
    "        if len(doc_text) <= preview_length:\n",
    "            preview_text = doc_text\n",
    "            ellipsis = \"\"\n",
    "        else:\n",
    "            # 截取前preview_length字，避免截断在中间（简单处理：以中文句末符号结束）\n",
    "            preview_text = doc_text[:preview_length]\n",
    "            # 若最后一个字符不是句末符号，找最近的句末符号截断\n",
    "            end_symbols = [\"。\", \"！\", \"？\", \"；\", \"】\", \")\", \"}\"]\n",
    "            last_symbol_idx = max([preview_text.rfind(s) for s in end_symbols if s in preview_text], default=-1)\n",
    "            if last_symbol_idx != -1 and last_symbol_idx > preview_length * 0.7:  # 确保保留70%以上内容\n",
    "                preview_text = preview_text[:last_symbol_idx + 1]\n",
    "            ellipsis = \"...\"\n",
    "        \n",
    "        # 2. 拼接文档详情（路径分相对+绝对，便于用户定位文件）\n",
    "        detailed_str += f\"\"\"\n",
    "#### 文档{idx}\n",
    "- **来源路径（相对路径）**: {doc[\"source\"]}\n",
    "- **完整路径（绝对路径）**: {doc[\"full_source_path\"]}\n",
    "- **检索类型**: {doc[\"search_type\"]}\n",
    "- **相关性分数**: {doc.get(\"rerank_score\", doc[\"score\"]):.4f}（分数越高越相关）\n",
    "- **文档时间戳**: {doc[\"timestamp\"] if doc[\"timestamp\"] else \"未记录\"}\n",
    "- **300字内容预览**: {preview_text}{ellipsis}\n",
    "\n",
    "{\"-\"*50}  # 分隔线，区分不同文档\n",
    "\"\"\"\n",
    "    return detailed_str\n",
    "\n",
    "# -------------------------- 4. 大模型调用与结果整合（新增文档详情展示） --------------------------\n",
    "def format_rag_for_llm(rag_results: List[Dict]) -> str:\n",
    "    \"\"\"给大模型的参考文档（简洁版，不影响回答生成）\"\"\"\n",
    "    if not rag_results:\n",
    "        return \"【无相关参考文档】\"\n",
    "    llm_ref = \"【相关参考文档】\\n\"\n",
    "    for i, res in enumerate(rag_results, 1):\n",
    "        preview = res[\"text\"]\n",
    "        llm_ref += f\"{i}. 来源：{res['source']} | 内容：{preview}\\n\"\n",
    "    return llm_ref\n",
    "\n",
    "def call_deepseek_v31(prompt: str, system_prompt: str) -> str:\n",
    "    \"\"\"调用DeepSeek-V3.1大模型生成回答\"\"\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {LLM_CONFIG['api_key']}\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": LLM_CONFIG[\"model_name\"],\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"max_tokens\": LLM_CONFIG[\"max_tokens\"],\n",
    "        \"temperature\": LLM_CONFIG[\"temperature\"],\n",
    "        \"stream\": False\n",
    "    }\n",
    "\n",
    "    for retry in range(LLM_CONFIG[\"max_retries\"]):\n",
    "        try:\n",
    "            response = requests.post(LLM_CONFIG[\"api_url\"], json=payload, headers=headers, timeout=60)\n",
    "            response.raise_for_status()\n",
    "            result = response.json()\n",
    "            if \"choices\" in result and result[\"choices\"]:\n",
    "                return result[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "            else:\n",
    "                raise ValueError(f\"大模型返回格式异常: {result}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"大模型调用失败（第{retry+1}/{LLM_CONFIG['max_retries']}次）: {e}\")\n",
    "            if retry < LLM_CONFIG[\"max_retries\"] - 1:\n",
    "                time.sleep(LLM_CONFIG[\"retry_delay\"])\n",
    "    return \"抱歉，大模型调用多次失败，请稍后重试。\"\n",
    "\n",
    "def rag_qa_pipeline(query: str, rag_searcher: HybridRAGSearcher) -> str:\n",
    "    \"\"\"端到端RAG问答流程：检索→生成回答→附加详细文档\"\"\"\n",
    "    # 1. RAG检索获取结果\n",
    "    rag_results = rag_searcher.search(query)\n",
    "    # 2. 生成大模型所需的简洁参考\n",
    "    llm_ref = format_rag_for_llm(rag_results)\n",
    "    # 3. 生成用户所需的详细文档详情（300字+路径）\n",
    "    detailed_docs = format_detailed_documents(\n",
    "        rag_results, \n",
    "        preview_length=RAG_CONFIG[\"doc_preview_length\"]\n",
    "    )\n",
    "\n",
    "    # 4. 大模型Prompt（引导基于参考回答）\n",
    "    system_prompt = \"\"\"你是基于检索增强（RAG）的专业问答助手，严格遵循：\n",
    "1. 必须优先使用【相关参考文档摘要】中的信息回答，每个结论需标注对应文档编号（如【参考1】）；\n",
    "2. 若参考文档信息不足，补充知识时需标注“注：以下内容基于模型自身知识补充”；\n",
    "3. 回答逻辑清晰，分点说明（适用时），不编造信息，无法回答则直接说明。\"\"\"\n",
    "    \n",
    "    user_prompt = f\"\"\"用户问题：{query}\n",
    "\n",
    "{llm_ref}\n",
    "\n",
    "请基于上述参考文档，回答用户问题。\"\"\"\n",
    "\n",
    "    # 5. 调用大模型生成回答\n",
    "    logger.info(\"调用DeepSeek-V3.1生成回答...\")\n",
    "    answer = call_deepseek_v31(user_prompt, system_prompt)\n",
    "\n",
    "    # 6. 整合最终输出（回答 + 详细文档）\n",
    "    final_output = f\"\"\"\n",
    "# RAG问答结果\n",
    "## 一、用户问题\n",
    "{query}\n",
    "\n",
    "## 二、AI回答\n",
    "{answer}\n",
    "\n",
    "## 三、检索统计信息\n",
    "- 检索到相关文档数量：{len(rag_results)} 条\n",
    "- 总检索耗时：{rag_results[0][\"retrieval_time\"]:.2f} 秒（含向量检索、关键词检索、重排序）\n",
    "- 检索类型：向量检索（语义匹配）+ 关键词检索（字面匹配）\n",
    "\n",
    "## 四、{detailed_docs}  # 插入详细文档（300字+路径）\n",
    "\n",
    "> 注：详细文档中的“完整路径（绝对路径）”可直接复制到文件管理器打开，查看文档全文。\n",
    "\"\"\"\n",
    "    return final_output\n",
    "\n",
    "# -------------------------- 5. 主函数（交互入口） --------------------------\n",
    "def main():\n",
    "    rag_searcher = None\n",
    "    try:\n",
    "        rag_searcher = HybridRAGSearcher(RAG_CONFIG)\n",
    "        print(\"=\"*100)\n",
    "        print(\"===== 带详细文档展示的RAG问答系统（基于DeepSeek-V3.1） =====\")\n",
    "        print(\"说明：输入问题后，将返回AI回答+检索文档详情（含300字内容+文件路径）\")\n",
    "        print(\"输入'退出'或'quit'可结束程序\")\n",
    "        print(\"=\"*100)\n",
    "        \n",
    "        while True:\n",
    "            user_query = input(\"\\n请输入你的问题：\").strip()\n",
    "            if user_query.lower() in [\"退出\", \"quit\", \"exit\"]:\n",
    "                print(\"\\n感谢使用，程序已退出！\")\n",
    "                break\n",
    "            if not user_query:\n",
    "                print(\"请输入有效的问题，不能为空！\")\n",
    "                continue\n",
    "            \n",
    "            # 执行问答流程并打印结果\n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            print(f\"正在处理问题：{user_query}\")\n",
    "            print(\"步骤1/2：RAG检索相关文档...\")\n",
    "            print(\"步骤2/2：调用大模型生成回答...\")\n",
    "            print(\"=\"*50)\n",
    "            \n",
    "            final_result = rag_qa_pipeline(user_query, rag_searcher)\n",
    "            print(\"\\n\" + \"=\"*100)\n",
    "            print(\"最终结果：\")\n",
    "            print(final_result)\n",
    "            print(\"=\"*100)\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"系统初始化失败: {e}\")\n",
    "        print(f\"\\n错误：系统初始化失败，原因：{str(e)}\")\n",
    "        print(\"请检查Milvus/Elasticsearch服务是否启动，或配置参数是否正确。\")\n",
    "    finally:\n",
    "        if rag_searcher:\n",
    "            rag_searcher.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade2e226-1c50-4122-96b0-43c2ff68bede",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
