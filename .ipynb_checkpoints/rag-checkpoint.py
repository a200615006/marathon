import os
import numpy as np
import torch
from typing import List, Dict, Any, Optional
from transformers import AutoModel, AutoTokenizer, AutoModelForSequenceClassification
from pymilvus import MilvusClient
from elasticsearch import Elasticsearch
from elasticsearch.exceptions import RequestError, ConnectionError
import json
import requests
import time
from datetime import datetime
import logging

# -------------------------- 1. åŸºç¤é…ç½®ï¼ˆç”¨æˆ¶å¯æ ¹æ“šå¯¦éš›ç’°å¢ƒèª¿æ•´ï¼‰ --------------------------
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# RAGæ ¸å¿ƒé…ç½®
RAG_CONFIG = {
    "milvus_db_path": "./milvus_data.db",
    "milvus_collection_name": "testchunks",
    "embedding_model_path": "./embedding-model",
    "reranker_model_path": "./reranker-model",
    "es_url": "https://localhost:9200",
    "es_username": "elastic",
    "es_password": "vSCQnhBXoox0sRo7-U1x",
    "es_index_name": "chunk_documents",
    "max_seq_length": 512,
    "rag_top_k": 3,  # æª¢ç´¢è¿”å›çš„topç›¸é—œçµæœæ•¸
    "doc_preview_length": 1000,  # æ–‡æª”å…§å®¹é è¦½é•·åº¦ï¼ˆå›ºå®š300å­—ï¼‰
    "es_connection_timeout": 5,  # Elasticsearché€£æ¥è¶…æ™‚æ™‚é–“ï¼ˆç§’ï¼‰
    "es_retry_count": 2  # Elasticsearché€£æ¥é‡è©¦æ¬¡æ•¸
}

#å¤§æ¨¡å‹é…ç½®
LLM_CONFIG = {
    "api_url": "your-llm-url",
    "api_key": "your-llm-apikey",
    "model_name": "deepseek-ai/DeepSeek-V3.1",
    "max_tokens": 2000,
    "temperature": 0.7,
    "max_retries": 3,
    "retry_delay": 5
}

# -------------------------- 2. æ··åˆRAGæª¢ç´¢ç³»çµ±ï¼ˆæ–°å¢ESæœå‹™æª¢æ¸¬ï¼‰ --------------------------
class HybridRAGSearcher:
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        logger.info(f"RAGæª¢ç´¢ç³»çµ±ä½¿ç”¨è¨­å‚™: {self.device}")

        self.embedding_tokenizer, self.embedding_model = self._init_embedding_model()
        self.reranker_tokenizer, self.reranker_model = self._init_reranker_model()
        self.milvus_client = self._init_milvus()
        
        # æ–°å¢ï¼šESæœå‹™æª¢æ¸¬èˆ‡åˆå§‹åŒ–
        self.es_client, self.es_available = self._init_elasticsearch_with_detection()
        
        # æ ¹æ“šESå¯ç”¨æ€§èª¿æ•´æª¢ç´¢ç­–ç•¥
        if self.es_available:
            logger.info("æ··åˆRAGæª¢ç´¢ç³»çµ±åˆå§‹åŒ–å®Œæˆï¼ˆMilvus + Elasticsearchï¼‰")
        else:
            logger.warning("æ··åˆRAGæª¢ç´¢ç³»çµ±åˆå§‹åŒ–å®Œæˆï¼ˆåƒ…Milvusï¼ŒElasticsearchä¸å¯ç”¨ï¼‰")

    def _init_embedding_model(self):
        try:
            tokenizer = AutoTokenizer.from_pretrained(self.config["embedding_model_path"])
            model = AutoModel.from_pretrained(self.config["embedding_model_path"]).to(self.device)
            model.eval()
            logger.info("BCEåµŒå…¥æ¨¡å‹åŠ è¼‰æˆåŠŸ")
            return tokenizer, model
        except Exception as e:
            logger.error(f"åµŒå…¥æ¨¡å‹åŠ è¼‰å¤±æ•—: {e}")
            raise

    def _init_reranker_model(self):
        try:
            tokenizer = AutoTokenizer.from_pretrained(self.config["reranker_model_path"])
            model = AutoModelForSequenceClassification.from_pretrained(self.config["reranker_model_path"]).to(self.device)
            model.eval()
            logger.info("BCEé‡æ’åºæ¨¡å‹åŠ è¼‰æˆåŠŸ")
            return tokenizer, model
        except Exception as e:
            logger.error(f"é‡æ’åºæ¨¡å‹åŠ è¼‰å¤±æ•—: {e}")
            raise

    def _init_milvus(self):
        try:
            client = MilvusClient(self.config["milvus_db_path"])
            collections = client.list_collections()
            if self.config["milvus_collection_name"] not in collections:
                raise ValueError(f"Milvusé›†åˆ '{self.config['milvus_collection_name']}' ä¸å­˜åœ¨")
            logger.info("Milvusé€£æ¥æˆåŠŸ")
            return client
        except Exception as e:
            logger.error(f"Milvusåˆå§‹åŒ–å¤±æ•—: {e}")
            raise

    def _init_elasticsearch_with_detection(self):
        """
        æ–°å¢ï¼šå¸¶æª¢æ¸¬åŠŸèƒ½çš„Elasticsearchåˆå§‹åŒ–
        Returns:
            tuple: (es_client, is_available)
        """
        max_retries = self.config.get("es_retry_count", 2)
        timeout = self.config.get("es_connection_timeout", 5)
        
        for attempt in range(max_retries + 1):
            try:
                logger.info(f"æ­£åœ¨æª¢æ¸¬Elasticsearchæœå‹™ï¼ˆç¬¬{attempt + 1}/{max_retries + 1}æ¬¡ï¼‰...")
                
                # å‰µå»ºESå®¢æˆ¶ç«¯
                client = Elasticsearch(
                    [self.config["es_url"]],
                    basic_auth=(self.config["es_username"], self.config["es_password"]),
                    verify_certs=False,
                    ssl_show_warn=False,
                    request_timeout=timeout,
                    retry_on_timeout=False
                )
                
                # æ¸¬è©¦é€£æ¥
                if client.ping():
                    # é€²ä¸€æ­¥æª¢æŸ¥ç´¢å¼•æ˜¯å¦å­˜åœ¨
                    if client.indices.exists(index=self.config["es_index_name"]):
                        logger.info("âœ… Elasticsearchæœå‹™æª¢æ¸¬æˆåŠŸï¼Œç´¢å¼•å­˜åœ¨")
                        return client, True
                    else:
                        logger.warning(f"âš ï¸  Elasticsearchæœå‹™å¯é”ï¼Œä½†ç´¢å¼• '{self.config['es_index_name']}' ä¸å­˜åœ¨")
                        return client, False
                else:
                    logger.warning(f"âŒ Elasticsearch pingå¤±æ•—ï¼ˆç¬¬{attempt + 1}æ¬¡ï¼‰")
                    
            except (ConnectionError, Exception) as e:
                logger.warning(f"âŒ Elasticsearché€£æ¥å¤±æ•—ï¼ˆç¬¬{attempt + 1}æ¬¡ï¼‰: {str(e)[:100]}...")
                
                # å¦‚æœä¸æ˜¯æœ€å¾Œä¸€æ¬¡å˜—è©¦ï¼Œç­‰å¾…å¾Œé‡è©¦
                if attempt < max_retries:
                    time.sleep(1)
        
        # æ‰€æœ‰å˜—è©¦å¤±æ•—
        logger.warning("ğŸ”„ Elasticsearchæœå‹™ä¸å¯ç”¨ï¼Œå°‡åƒ…ä½¿ç”¨Milvusé€²è¡Œå‘é‡æª¢ç´¢")
        return None, False

    def _generate_embedding(self, texts: List[str]) -> np.ndarray:
        with torch.no_grad():
            inputs = self.embedding_tokenizer(
                texts, padding=True, truncation=True, max_length=self.config["max_seq_length"], return_tensors="pt"
            ).to(self.device)
            outputs = self.embedding_model(**inputs)
            cls_emb = outputs.last_hidden_state[:, 0, :]
            return (cls_emb / cls_emb.norm(dim=1, keepdim=True)).cpu().numpy()

    def _vector_search(self, query: str) -> List[Dict]:
        try:
            query_emb = self._generate_embedding([query])[0].tolist()
            
            # å¦‚æœESä¸å¯ç”¨ï¼Œå¢åŠ Milvusæª¢ç´¢æ•¸é‡ä»¥è£œå„Ÿ
            search_limit = self.config["rag_top_k"] * 2
            if not self.es_available:
                search_limit = self.config["rag_top_k"] * 4  # å¢åŠ æª¢ç´¢æ•¸é‡
                
            results = self.milvus_client.search(
                collection_name=self.config["milvus_collection_name"],
                anns_field="vector",
                data=[query_emb],
                limit=search_limit,
                output_fields=["text", "folder", "file", "timestamp"]
            )
            return [
                {
                    "id": f"milvus_{hit['id']}",
                    "text": hit["entity"]["text"],
                    "source": f"{hit['entity']['folder']}/{hit['entity']['file']}",
                    "full_source_path": os.path.abspath(f"{hit['entity']['folder']}/{hit['entity']['file']}"),
                    "score": 1.0 / (1.0 + hit["distance"]),
                    "search_type": "å‘é‡æª¢ç´¢",
                    "timestamp": hit["entity"].get("timestamp", "")
                }
                for hit in results[0]
            ]
        except Exception as e:
            logger.error(f"å‘é‡æœç´¢å¤±æ•—: {e}")
            return []

    def _keyword_search(self, query: str) -> List[Dict]:
        """ä¿®æ”¹ï¼šåªåœ¨ESå¯ç”¨æ™‚åŸ·è¡Œé—œéµè©æœç´¢"""
        if not self.es_available:
            logger.debug("Elasticsearchä¸å¯ç”¨ï¼Œè·³éé—œéµè©æª¢ç´¢")
            return []
            
        try:
            response = self.es_client.search(
                index=self.config["es_index_name"],
                body={"query": {"match": {"content": query}}, "size": self.config["rag_top_k"] * 2}
            )
            return [
                {
                    "id": f"es_{hit['_id']}",
                    "text": hit["_source"]["content"],
                    "source": f"{hit['_source']['folder']}/{hit['_source']['filename']}",
                    "full_source_path": os.path.abspath(f"{hit['_source']['folder']}/{hit['_source']['filename']}"),
                    "score": hit["_score"] / 100.0,
                    "search_type": "é—œéµè©æª¢ç´¢",
                    "timestamp": hit["_source"].get("import_time", "")
                }
                for hit in response["hits"]["hits"]
            ]
        except Exception as e:
            logger.error(f"é—œéµè©æœç´¢å¤±æ•—: {e}")
            # ESæœç´¢å¤±æ•—æ™‚ï¼Œæ¨™è¨˜ç‚ºä¸å¯ç”¨
            self.es_available = False
            logger.warning("Elasticsearchæœç´¢å¤±æ•—ï¼Œå¾ŒçºŒå°‡åƒ…ä½¿ç”¨Milvus")
            return []

    def _merge_deduplicate(self, vector_res: List[Dict], keyword_res: List[Dict]) -> List[Dict]:
        seen = set()
        merged = []
        for res in vector_res + keyword_res:
            text_key = res["text"][:100]
            if text_key not in seen:
                seen.add(text_key)
                merged.append(res)
        
        # æ ¹æ“šESå¯ç”¨æ€§èª¿æ•´çµæœæ•¸é‡
        result_count = self.config["rag_top_k"] * 3
        if not self.es_available:
            result_count = self.config["rag_top_k"] * 2  # åƒ…å‘é‡æª¢ç´¢æ™‚é©ç•¶æ¸›å°‘
            
        return sorted(merged, key=lambda x: x["score"], reverse=True)[:result_count]

    def _rerank(self, query: str, results: List[Dict]) -> List[Dict]:
        if not results:
            return []
        try:
            max_doc_len = self.config["max_seq_length"] - len(self.reranker_tokenizer.tokenize(query)) - 3
            pairs = [[query, res["text"][:max_doc_len]] for res in results]
            
            with torch.no_grad():
                inputs = self.reranker_tokenizer(
                    pairs, padding=True, truncation=True, max_length=self.config["max_seq_length"], return_tensors="pt"
                ).to(self.device)
                scores = torch.sigmoid(self.reranker_model(**inputs).logits.view(-1,)).cpu().tolist()
            
            for res, score in zip(results, scores):
                res["rerank_score"] = score
            return sorted(results, key=lambda x: x["rerank_score"], reverse=True)[:self.config["rag_top_k"]]
        except Exception as e:
            logger.error(f"é‡æ’åºå¤±æ•—: {e}")
            return sorted(results, key=lambda x: x["score"], reverse=True)[:self.config["rag_top_k"]]

    def search(self, query: str) -> List[Dict]:
        search_mode = "æ··åˆæª¢ç´¢ï¼ˆå‘é‡+é—œéµè©ï¼‰" if self.es_available else "ç´”å‘é‡æª¢ç´¢"
        logger.info(f"é–‹å§‹RAGæª¢ç´¢ï¼ˆ{search_mode}ï¼‰ï¼ŒæŸ¥è©¢: {query[:50]}...")
        
        start = datetime.now()
        vector_res = self._vector_search(query)
        keyword_res = self._keyword_search(query)  # å…§éƒ¨æœƒæª¢æŸ¥ESå¯ç”¨æ€§
        merged_res = self._merge_deduplicate(vector_res, keyword_res)
        final_res = self._rerank(query, merged_res)
        
        # è£œå……æª¢ç´¢è€—æ™‚å’Œæª¢ç´¢æ¨¡å¼ä¿¡æ¯
        retrieval_time = (datetime.now() - start).total_seconds()
        for res in final_res:
            res["retrieval_time"] = retrieval_time
            res["search_mode"] = search_mode
            
        logger.info(f"RAGæª¢ç´¢å®Œæˆï¼ˆ{search_mode}ï¼‰ï¼Œç²å– {len(final_res)} æ¢ç›¸é—œçµæœï¼Œè€—æ™‚ {retrieval_time:.2f} ç§’")
        return final_res

    def get_service_status(self) -> Dict[str, Any]:
        """æ–°å¢ï¼šç²å–æœå‹™ç‹€æ…‹ä¿¡æ¯"""
        return {
            "milvus_available": True,  # Milvusåœ¨åˆå§‹åŒ–æ™‚å·²ç¢ºä¿å¯ç”¨
            "elasticsearch_available": self.es_available,
            "search_mode": "æ··åˆæª¢ç´¢ï¼ˆå‘é‡+é—œéµè©ï¼‰" if self.es_available else "ç´”å‘é‡æª¢ç´¢"
        }

    def close(self):
        if self.milvus_client:
            self.milvus_client.close()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        logger.info("RAGæª¢ç´¢ç³»çµ±è³‡æºå·²é‡‹æ”¾")

# -------------------------- 3. æ–‡æª”ä¿¡æ¯æ ¼å¼åŒ–ï¼ˆæ–°å¢æœå‹™ç‹€æ…‹å±•ç¤ºï¼‰ --------------------------
def format_detailed_documents(rag_results: List[Dict], preview_length: int = 300) -> str:
    """
    æ ¼å¼åŒ–æª¢ç´¢æ–‡æª”è©³æƒ…ï¼šåŒ…å«å®Œæ•´è·¯å¾‘ï¼ˆç›¸å°+çµ•å°ï¼‰ã€æª¢ç´¢é¡å‹ã€åˆ†æ•¸ã€300å­—å…§å®¹
    """
    if not rag_results:
        return "ã€æœªæª¢ç´¢åˆ°ç›¸é—œæ–‡æª”ã€‘\n"
    
    # ç²å–æª¢ç´¢æ¨¡å¼ï¼ˆå¾ç¬¬ä¸€å€‹çµæœä¸­æå–ï¼‰
    search_mode = rag_results[0].get("search_mode", "æœªçŸ¥æª¢ç´¢æ¨¡å¼")
    detailed_str = f"### è©³ç´°æª¢ç´¢æ–‡æª”ï¼ˆå…±{len(rag_results)}æ¢ï¼Œæª¢ç´¢æ¨¡å¼ï¼š{search_mode}ï¼‰\n"
    
    for idx, doc in enumerate(rag_results, 1):
        # è™•ç†æ–‡æª”å…§å®¹
        doc_text = doc["text"].strip()
        if len(doc_text) <= preview_length:
            preview_text = doc_text
            ellipsis = ""
        else:
            preview_text = doc_text[:preview_length]
            end_symbols = ["ã€‚", "ï¼", "ï¼Ÿ", "ï¼›", "ã€‘", ")", "}"]
            last_symbol_idx = max([preview_text.rfind(s) for s in end_symbols if s in preview_text], default=-1)
            if last_symbol_idx != -1 and last_symbol_idx > preview_length * 0.7:
                preview_text = preview_text[:last_symbol_idx + 1]
            ellipsis = "..."
        
        # æ‹¼æ¥æ–‡æª”è©³æƒ…
        detailed_str += f"""
#### æ–‡æª”{idx}
- **ä¾†æºè·¯å¾‘ï¼ˆç›¸å°è·¯å¾‘ï¼‰**: {doc["source"]}
- **å®Œæ•´è·¯å¾‘ï¼ˆçµ•å°è·¯å¾‘ï¼‰**: {doc["full_source_path"]}
- **æª¢ç´¢é¡å‹**: {doc["search_type"]}
- **ç›¸é—œæ€§åˆ†æ•¸**: {doc.get("rerank_score", doc["score"]):.4f}ï¼ˆåˆ†æ•¸è¶Šé«˜è¶Šç›¸é—œï¼‰
- **æ–‡æª”æ™‚é–“æˆ³**: {doc["timestamp"] if doc["timestamp"] else "æœªè¨˜éŒ„"}
- **300å­—å…§å®¹é è¦½**: {preview_text}{ellipsis}

{"-"*50}
"""
    return detailed_str

# -------------------------- 4. å¤§æ¨¡å‹èª¿ç”¨èˆ‡çµæœæ•´åˆ --------------------------
def format_rag_for_llm(rag_results: List[Dict]) -> str:
    """çµ¦å¤§æ¨¡å‹çš„åƒè€ƒæ–‡æª”ï¼ˆç°¡æ½”ç‰ˆï¼‰"""
    if not rag_results:
        return "ã€ç„¡ç›¸é—œåƒè€ƒæ–‡æª”ã€‘"
    llm_ref = "ã€ç›¸é—œåƒè€ƒæ–‡æª”ã€‘\n"
    for i, res in enumerate(rag_results, 1):
        preview = res["text"]
        llm_ref += f"{i}. ä¾†æºï¼š{res['source']} | å…§å®¹ï¼š{preview}\n"
    return llm_ref

def call_deepseek_v31(prompt: str, system_prompt: str) -> str:
    """èª¿ç”¨DeepSeek-V3.1å¤§æ¨¡å‹ç”Ÿæˆå›ç­”"""
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {LLM_CONFIG['api_key']}"
    }
    payload = {
        "model": LLM_CONFIG["model_name"],
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": prompt}
        ],
        "max_tokens": LLM_CONFIG["max_tokens"],
        "temperature": LLM_CONFIG["temperature"],
        "stream": False
    }

    for retry in range(LLM_CONFIG["max_retries"]):
        try:
            response = requests.post(LLM_CONFIG["api_url"], json=payload, headers=headers, timeout=60)
            response.raise_for_status()
            result = response.json()
            if "choices" in result and result["choices"]:
                return result["choices"][0]["message"]["content"].strip()
            else:
                raise ValueError(f"å¤§æ¨¡å‹è¿”å›æ ¼å¼ç•°å¸¸: {result}")
        except Exception as e:
            logger.error(f"å¤§æ¨¡å‹èª¿ç”¨å¤±æ•—ï¼ˆç¬¬{retry+1}/{LLM_CONFIG['max_retries']}æ¬¡ï¼‰: {e}")
            if retry < LLM_CONFIG["max_retries"] - 1:
                time.sleep(LLM_CONFIG["retry_delay"])
    return "æŠ±æ­‰ï¼Œå¤§æ¨¡å‹èª¿ç”¨å¤šæ¬¡å¤±æ•—ï¼Œè«‹ç¨å¾Œé‡è©¦ã€‚"

def rag_qa_pipeline(query: str, rag_searcher: HybridRAGSearcher) -> str:
    """ç«¯åˆ°ç«¯RAGå•ç­”æµç¨‹"""
    # 1. RAGæª¢ç´¢ç²å–çµæœ
    rag_results = rag_searcher.search(query)
    # 2. ç”Ÿæˆå¤§æ¨¡å‹æ‰€éœ€çš„ç°¡æ½”åƒè€ƒ
    llm_ref = format_rag_for_llm(rag_results)
    # 3. ç”Ÿæˆç”¨æˆ¶æ‰€éœ€çš„è©³ç´°æ–‡æª”è©³æƒ…
    detailed_docs = format_detailed_documents(
        rag_results, 
        preview_length=RAG_CONFIG["doc_preview_length"]
    )

    # 4. å¤§æ¨¡å‹Prompt
    system_prompt = """ä½ æ˜¯åŸºæ–¼æª¢ç´¢å¢å¼·ï¼ˆRAGï¼‰çš„å°ˆæ¥­å•ç­”åŠ©æ‰‹ï¼Œåš´æ ¼éµå¾ªï¼š
1. å¿…é ˆå„ªå…ˆä½¿ç”¨ã€ç›¸é—œåƒè€ƒæ–‡æª”æ‘˜è¦ã€‘ä¸­çš„ä¿¡æ¯å›ç­”ï¼Œæ¯å€‹çµè«–éœ€æ¨™è¨»å°æ‡‰æ–‡æª”ç·¨è™Ÿï¼ˆå¦‚ã€åƒè€ƒ1ã€‘ï¼‰ï¼›
2. è‹¥åƒè€ƒæ–‡æª”ä¿¡æ¯ä¸è¶³ï¼Œè£œå……çŸ¥è­˜æ™‚éœ€æ¨™è¨»"æ³¨ï¼šä»¥ä¸‹å…§å®¹åŸºæ–¼æ¨¡å‹è‡ªèº«çŸ¥è­˜è£œå……"ï¼›
3. å›ç­”é‚è¼¯æ¸…æ™°ï¼Œåˆ†é»èªªæ˜ï¼ˆé©ç”¨æ™‚ï¼‰ï¼Œä¸ç·¨é€ ä¿¡æ¯ï¼Œç„¡æ³•å›ç­”å‰‡ç›´æ¥èªªæ˜ã€‚"""
    
    user_prompt = f"""ç”¨æˆ¶å•é¡Œï¼š{query}

{llm_ref}

è«‹åŸºæ–¼ä¸Šè¿°åƒè€ƒæ–‡æª”ï¼Œå›ç­”ç”¨æˆ¶å•é¡Œã€‚"""

    # 5. èª¿ç”¨å¤§æ¨¡å‹ç”Ÿæˆå›ç­”
    logger.info("èª¿ç”¨DeepSeek-V3.1ç”Ÿæˆå›ç­”...")
    answer = call_deepseek_v31(user_prompt, system_prompt)

    # 6. ç²å–æœå‹™ç‹€æ…‹
    service_status = rag_searcher.get_service_status()

    # 7. æ•´åˆæœ€çµ‚è¼¸å‡º
    final_output = f"""
# RAGå•ç­”çµæœ
## ä¸€ã€ç”¨æˆ¶å•é¡Œ
{query}

## äºŒã€AIå›ç­”
{answer}

## ä¸‰ã€æª¢ç´¢çµ±è¨ˆä¿¡æ¯
- æª¢ç´¢åˆ°ç›¸é—œæ–‡æª”æ•¸é‡ï¼š{len(rag_results)} æ¢
- ç¸½æª¢ç´¢è€—æ™‚ï¼š{rag_results[0]["retrieval_time"]:.2f} ç§’ï¼ˆå«å‘é‡æª¢ç´¢ã€é—œéµè©æª¢ç´¢ã€é‡æ’åºï¼‰
- æª¢ç´¢æ¨¡å¼ï¼š{service_status["search_mode"]}
- æœå‹™ç‹€æ…‹ï¼šMilvus âœ… | Elasticsearch {'âœ…' if service_status['elasticsearch_available'] else 'âŒ'}

## å››ã€{detailed_docs}

> æ³¨ï¼šè©³ç´°æ–‡æª”ä¸­çš„"å®Œæ•´è·¯å¾‘ï¼ˆçµ•å°è·¯å¾‘ï¼‰"å¯ç›´æ¥è¤‡è£½åˆ°æ–‡ä»¶ç®¡ç†å™¨æ‰“é–‹ï¼ŒæŸ¥çœ‹æ–‡æª”å…¨æ–‡ã€‚
"""
    return final_output

# -------------------------- 5. ä¸»å‡½æ•¸ï¼ˆæ–°å¢æœå‹™ç‹€æ…‹æç¤ºï¼‰ --------------------------
def main():
    rag_searcher = None
    try:
        rag_searcher = HybridRAGSearcher(RAG_CONFIG)
        service_status = rag_searcher.get_service_status()
        
        print("="*100)
        print("===== å¸¶è©³ç´°æ–‡æª”å±•ç¤ºçš„RAGå•ç­”ç³»çµ±ï¼ˆåŸºæ–¼DeepSeek-V3.1ï¼‰ =====")
        print(f"ç•¶å‰æª¢ç´¢æ¨¡å¼ï¼š{service_status['search_mode']}")
        print(f"æœå‹™ç‹€æ…‹ï¼šMilvus âœ… | Elasticsearch {'âœ…' if service_status['elasticsearch_available'] else 'âŒ'}")
        if not service_status['elasticsearch_available']:
            print("âš ï¸  æ³¨æ„ï¼šElasticsearchæœå‹™ä¸å¯ç”¨ï¼Œå°‡åƒ…ä½¿ç”¨Milvusé€²è¡Œå‘é‡æª¢ç´¢")
        print("èªªæ˜ï¼šè¼¸å…¥å•é¡Œå¾Œï¼Œå°‡è¿”å›AIå›ç­”+æª¢ç´¢æ–‡æª”è©³æƒ…ï¼ˆå«300å­—å…§å®¹+æ–‡ä»¶è·¯å¾‘ï¼‰")
        print("è¼¸å…¥'é€€å‡º'æˆ–'quit'å¯çµæŸç¨‹åº")
        print("="*100)
        
        while True:
            user_query = input("\nè«‹è¼¸å…¥ä½ çš„å•é¡Œï¼š").strip()
            if user_query.lower() in ["é€€å‡º", "quit", "exit"]:
                print("\næ„Ÿè¬ä½¿ç”¨ï¼Œç¨‹åºå·²é€€å‡ºï¼")
                break
            if not user_query:
                print("è«‹è¼¸å…¥æœ‰æ•ˆçš„å•é¡Œï¼Œä¸èƒ½ç‚ºç©ºï¼")
                continue
            
            # åŸ·è¡Œå•ç­”æµç¨‹ä¸¦æ‰“å°çµæœ
            print("\n" + "="*50)
            print(f"æ­£åœ¨è™•ç†å•é¡Œï¼š{user_query}")
            print("æ­¥é©Ÿ1/2ï¼šRAGæª¢ç´¢ç›¸é—œæ–‡æª”...")
            print("æ­¥é©Ÿ2/2ï¼šèª¿ç”¨å¤§æ¨¡å‹ç”Ÿæˆå›ç­”...")
            print("="*50)
            
            final_result = rag_qa_pipeline(user_query, rag_searcher)
            print("\n" + "="*100)
            print("æœ€çµ‚çµæœï¼š")
            print(final_result)
            print("="*100)
            
    except Exception as e:
        logger.error(f"ç³»çµ±åˆå§‹åŒ–å¤±æ•—: {e}")
        print(f"\néŒ¯èª¤ï¼šç³»çµ±åˆå§‹åŒ–å¤±æ•—ï¼ŒåŸå› ï¼š{str(e)}")
        print("è«‹æª¢æŸ¥Milvusæœå‹™æ˜¯å¦å•Ÿå‹•ï¼Œæˆ–é…ç½®åƒæ•¸æ˜¯å¦æ­£ç¢ºã€‚")
    finally:
        if rag_searcher:
            rag_searcher.close()

if __name__ == "__main__":
    main()
